{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python 3.10\n",
    "# source .venv/bin/activate\n",
    "\n",
    "#tensorflow-gpu==2.10.0\n",
    "#pandas\n",
    "#scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, InputLayer, LSTM\n",
    "from tensorflow.keras.optimizers import  Adam\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lastfm_url</th>\n",
       "      <th>track</th>\n",
       "      <th>artist</th>\n",
       "      <th>seeds</th>\n",
       "      <th>number_of_emotion_tags</th>\n",
       "      <th>valence_tags</th>\n",
       "      <th>arousal_tags</th>\n",
       "      <th>dominance_tags</th>\n",
       "      <th>mbid</th>\n",
       "      <th>spotify_id</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.last.fm/music/eminem/_/%2527till%2...</td>\n",
       "      <td>'Till I Collapse</td>\n",
       "      <td>Eminem</td>\n",
       "      <td>[aggressive]</td>\n",
       "      <td>6</td>\n",
       "      <td>4.550000</td>\n",
       "      <td>5.273125</td>\n",
       "      <td>5.690625</td>\n",
       "      <td>cab93def-26c5-4fb0-bedd-26ec4c1619e1</td>\n",
       "      <td>4xkOaSrkexMciUUogZKVTS</td>\n",
       "      <td>rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.last.fm/music/metallica/_/st.%2banger</td>\n",
       "      <td>St. Anger</td>\n",
       "      <td>Metallica</td>\n",
       "      <td>[aggressive]</td>\n",
       "      <td>8</td>\n",
       "      <td>3.710000</td>\n",
       "      <td>5.833000</td>\n",
       "      <td>5.427250</td>\n",
       "      <td>727a2529-7ee8-4860-aef6-7959884895cb</td>\n",
       "      <td>3fOc9x06lKJBhz435mInlH</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.last.fm/music/rick%2bross/_/speedi...</td>\n",
       "      <td>Speedin'</td>\n",
       "      <td>Rick Ross</td>\n",
       "      <td>[aggressive]</td>\n",
       "      <td>1</td>\n",
       "      <td>3.080000</td>\n",
       "      <td>5.870000</td>\n",
       "      <td>5.490000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3Y96xd4Ce0J47dcalLrEC8</td>\n",
       "      <td>rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.last.fm/music/m.i.a./_/bamboo%2bbanga</td>\n",
       "      <td>Bamboo Banga</td>\n",
       "      <td>M.I.A.</td>\n",
       "      <td>[aggressive, fun, sexy, energetic]</td>\n",
       "      <td>13</td>\n",
       "      <td>6.555071</td>\n",
       "      <td>5.537214</td>\n",
       "      <td>5.691357</td>\n",
       "      <td>99dd2c8c-e7c1-413e-8ea4-4497a00ffa18</td>\n",
       "      <td>6tqFC1DIOphJkCwrjVzPmg</td>\n",
       "      <td>hip-hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.last.fm/music/dope/_/die%2bmf%2bdie</td>\n",
       "      <td>Die MF Die</td>\n",
       "      <td>Dope</td>\n",
       "      <td>[aggressive]</td>\n",
       "      <td>7</td>\n",
       "      <td>3.771176</td>\n",
       "      <td>5.348235</td>\n",
       "      <td>5.441765</td>\n",
       "      <td>b9eb3484-5e0e-4690-ab5a-ca91937032a5</td>\n",
       "      <td>5bU4KX47KqtDKKaLM4QCzh</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.last.fm/music/drowning%2bpool/_/st...</td>\n",
       "      <td>Step Up</td>\n",
       "      <td>Drowning Pool</td>\n",
       "      <td>[aggressive]</td>\n",
       "      <td>9</td>\n",
       "      <td>2.971389</td>\n",
       "      <td>5.537500</td>\n",
       "      <td>4.726389</td>\n",
       "      <td>49e7b4d2-3772-4301-ba25-3cc46ceb342e</td>\n",
       "      <td>4Q1w4Ryyi8KNxxaFlOQClK</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.last.fm/music/kanye%2bwest/_/feedback</td>\n",
       "      <td>Feedback</td>\n",
       "      <td>Kanye West</td>\n",
       "      <td>[aggressive]</td>\n",
       "      <td>1</td>\n",
       "      <td>3.080000</td>\n",
       "      <td>5.870000</td>\n",
       "      <td>5.490000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49fT6owWuknekShh9utsjv</td>\n",
       "      <td>hip-hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.last.fm/music/deftones/_/7%2bwords</td>\n",
       "      <td>7 Words</td>\n",
       "      <td>Deftones</td>\n",
       "      <td>[aggressive, angry]</td>\n",
       "      <td>10</td>\n",
       "      <td>3.807121</td>\n",
       "      <td>5.473939</td>\n",
       "      <td>4.729091</td>\n",
       "      <td>1a826083-5585-445f-a708-415dc90aa050</td>\n",
       "      <td>6DoXuH326aAYEN8CnlLmhP</td>\n",
       "      <td>nu metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://www.last.fm/music/fiona%2bapple/_/limp</td>\n",
       "      <td>Limp</td>\n",
       "      <td>Fiona Apple</td>\n",
       "      <td>[aggressive, angry, bitter]</td>\n",
       "      <td>20</td>\n",
       "      <td>3.737211</td>\n",
       "      <td>5.610204</td>\n",
       "      <td>4.626735</td>\n",
       "      <td>4435982c-b83e-4daa-af2b-9f3430036bb7</td>\n",
       "      <td>104YdibC7VQy78xAVmgRYr</td>\n",
       "      <td>singer-songwriter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.last.fm/music/metallica/_/sweet%2b...</td>\n",
       "      <td>Sweet Amber</td>\n",
       "      <td>Metallica</td>\n",
       "      <td>[aggressive]</td>\n",
       "      <td>4</td>\n",
       "      <td>3.582759</td>\n",
       "      <td>5.757241</td>\n",
       "      <td>5.340000</td>\n",
       "      <td>fe1cc051-faa7-4953-b331-f6196cd3ddae</td>\n",
       "      <td>5fU6qjmD38P90BMsuqpiuU</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://www.last.fm/music/black%2bflag/_/depre...</td>\n",
       "      <td>Depression</td>\n",
       "      <td>Black Flag</td>\n",
       "      <td>[aggressive]</td>\n",
       "      <td>9</td>\n",
       "      <td>3.259444</td>\n",
       "      <td>5.203056</td>\n",
       "      <td>4.422778</td>\n",
       "      <td>585398ed-1275-4579-9451-e8dd7db9d59c</td>\n",
       "      <td>1qxkzHlZBXFv5HfyYqJ8cy</td>\n",
       "      <td>punk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.last.fm/music/pendulum/_/comprachicos</td>\n",
       "      <td>Comprachicos</td>\n",
       "      <td>Pendulum</td>\n",
       "      <td>[aggressive, epic]</td>\n",
       "      <td>4</td>\n",
       "      <td>5.754167</td>\n",
       "      <td>5.565333</td>\n",
       "      <td>5.836500</td>\n",
       "      <td>a3c325ce-fac4-42b9-85da-b3c9e0f243af</td>\n",
       "      <td>2ZIJUwprFZrAaZCRKYfAno</td>\n",
       "      <td>industrial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://www.last.fm/music/deftones/_/when%2bgi...</td>\n",
       "      <td>When Girls Telephone Boys</td>\n",
       "      <td>Deftones</td>\n",
       "      <td>[aggressive, angry, driving, energetic]</td>\n",
       "      <td>8</td>\n",
       "      <td>3.910741</td>\n",
       "      <td>4.915556</td>\n",
       "      <td>4.631852</td>\n",
       "      <td>3bc2c1a9-43bc-45b2-87fc-4313eb2534fe</td>\n",
       "      <td>6xK3sBdRm99g9T8Ov0gjdF</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://www.last.fm/music/kanye%2bwest/_/two%2...</td>\n",
       "      <td>Two Words</td>\n",
       "      <td>Kanye West</td>\n",
       "      <td>[aggressive, energetic]</td>\n",
       "      <td>3</td>\n",
       "      <td>4.564286</td>\n",
       "      <td>5.130000</td>\n",
       "      <td>4.842857</td>\n",
       "      <td>f6cc8417-e590-494c-aba9-e3cbc536442d</td>\n",
       "      <td>62wtttQzoIA9HnNmGVd9Yq</td>\n",
       "      <td>hip-hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>https://www.last.fm/music/black%2bflag/_/what%...</td>\n",
       "      <td>What I See</td>\n",
       "      <td>Black Flag</td>\n",
       "      <td>[aggressive, angry]</td>\n",
       "      <td>7</td>\n",
       "      <td>3.205476</td>\n",
       "      <td>5.026905</td>\n",
       "      <td>4.584762</td>\n",
       "      <td>8050e7e7-2c7a-4390-bf77-eaedf293c626</td>\n",
       "      <td>3DaC3oRpGInTU0x8DvdSGp</td>\n",
       "      <td>punk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://www.last.fm/music/lamb%2bof%2bgod/_/re...</td>\n",
       "      <td>Requiem</td>\n",
       "      <td>Lamb of God</td>\n",
       "      <td>[aggressive]</td>\n",
       "      <td>2</td>\n",
       "      <td>2.970000</td>\n",
       "      <td>5.936000</td>\n",
       "      <td>5.214000</td>\n",
       "      <td>23b46286-3b27-431b-8943-9be9d37836f9</td>\n",
       "      <td>0DxYrFOfiFShTbO2XdFpBX</td>\n",
       "      <td>metalcore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>https://www.last.fm/music/black%2bflag/_/room%...</td>\n",
       "      <td>Room 13</td>\n",
       "      <td>Black Flag</td>\n",
       "      <td>[aggressive, angry]</td>\n",
       "      <td>8</td>\n",
       "      <td>3.285000</td>\n",
       "      <td>5.297222</td>\n",
       "      <td>4.716296</td>\n",
       "      <td>b83fe0b7-d40d-4e77-9b2b-606d36e4a391</td>\n",
       "      <td>7EZlzu01NzbR1jWEIDSk5T</td>\n",
       "      <td>punk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>https://www.last.fm/music/mystikal/_/shake%2by...</td>\n",
       "      <td>Shake Ya Ass</td>\n",
       "      <td>Mystikal</td>\n",
       "      <td>[aggressive]</td>\n",
       "      <td>11</td>\n",
       "      <td>5.680882</td>\n",
       "      <td>5.751912</td>\n",
       "      <td>5.930882</td>\n",
       "      <td>bf2761fe-8b4d-4cc8-bdea-0ccda7c3fed1</td>\n",
       "      <td>1jRzdY7oUBOhrylNtiMtBD</td>\n",
       "      <td>hip-hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>https://www.last.fm/music/deftones/_/combat</td>\n",
       "      <td>Combat</td>\n",
       "      <td>Deftones</td>\n",
       "      <td>[aggressive, intense, epic, uplifting]</td>\n",
       "      <td>7</td>\n",
       "      <td>5.104098</td>\n",
       "      <td>5.476230</td>\n",
       "      <td>5.244672</td>\n",
       "      <td>1b49361a-e594-490c-aa60-dde81b235d24</td>\n",
       "      <td>2tdzFXOsJLLI20QdnSqxr1</td>\n",
       "      <td>alternative metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>https://www.last.fm/music/fugazi/_/glue%2bman</td>\n",
       "      <td>Glue Man</td>\n",
       "      <td>Fugazi</td>\n",
       "      <td>[aggressive, confrontational, intense, epic, d...</td>\n",
       "      <td>7</td>\n",
       "      <td>3.838627</td>\n",
       "      <td>4.418725</td>\n",
       "      <td>4.059804</td>\n",
       "      <td>9e387cb2-843f-4db0-a0eb-8ba677dfd93d</td>\n",
       "      <td>1Nvy8JAL3DrO0a6xdgJSvv</td>\n",
       "      <td>punk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           lastfm_url  \\\n",
       "0   https://www.last.fm/music/eminem/_/%2527till%2...   \n",
       "1   https://www.last.fm/music/metallica/_/st.%2banger   \n",
       "2   https://www.last.fm/music/rick%2bross/_/speedi...   \n",
       "3   https://www.last.fm/music/m.i.a./_/bamboo%2bbanga   \n",
       "4     https://www.last.fm/music/dope/_/die%2bmf%2bdie   \n",
       "5   https://www.last.fm/music/drowning%2bpool/_/st...   \n",
       "6   https://www.last.fm/music/kanye%2bwest/_/feedback   \n",
       "7      https://www.last.fm/music/deftones/_/7%2bwords   \n",
       "8      https://www.last.fm/music/fiona%2bapple/_/limp   \n",
       "9   https://www.last.fm/music/metallica/_/sweet%2b...   \n",
       "10  https://www.last.fm/music/black%2bflag/_/depre...   \n",
       "11  https://www.last.fm/music/pendulum/_/comprachicos   \n",
       "12  https://www.last.fm/music/deftones/_/when%2bgi...   \n",
       "13  https://www.last.fm/music/kanye%2bwest/_/two%2...   \n",
       "14  https://www.last.fm/music/black%2bflag/_/what%...   \n",
       "15  https://www.last.fm/music/lamb%2bof%2bgod/_/re...   \n",
       "16  https://www.last.fm/music/black%2bflag/_/room%...   \n",
       "17  https://www.last.fm/music/mystikal/_/shake%2by...   \n",
       "18        https://www.last.fm/music/deftones/_/combat   \n",
       "19      https://www.last.fm/music/fugazi/_/glue%2bman   \n",
       "\n",
       "                        track         artist  \\\n",
       "0            'Till I Collapse         Eminem   \n",
       "1                   St. Anger      Metallica   \n",
       "2                    Speedin'      Rick Ross   \n",
       "3                Bamboo Banga         M.I.A.   \n",
       "4                  Die MF Die           Dope   \n",
       "5                     Step Up  Drowning Pool   \n",
       "6                    Feedback     Kanye West   \n",
       "7                     7 Words       Deftones   \n",
       "8                        Limp    Fiona Apple   \n",
       "9                 Sweet Amber      Metallica   \n",
       "10                 Depression     Black Flag   \n",
       "11               Comprachicos       Pendulum   \n",
       "12  When Girls Telephone Boys       Deftones   \n",
       "13                  Two Words     Kanye West   \n",
       "14                 What I See     Black Flag   \n",
       "15                    Requiem    Lamb of God   \n",
       "16                    Room 13     Black Flag   \n",
       "17               Shake Ya Ass       Mystikal   \n",
       "18                     Combat       Deftones   \n",
       "19                   Glue Man         Fugazi   \n",
       "\n",
       "                                                seeds  number_of_emotion_tags  \\\n",
       "0                                        [aggressive]                       6   \n",
       "1                                        [aggressive]                       8   \n",
       "2                                        [aggressive]                       1   \n",
       "3                  [aggressive, fun, sexy, energetic]                      13   \n",
       "4                                        [aggressive]                       7   \n",
       "5                                        [aggressive]                       9   \n",
       "6                                        [aggressive]                       1   \n",
       "7                                 [aggressive, angry]                      10   \n",
       "8                         [aggressive, angry, bitter]                      20   \n",
       "9                                        [aggressive]                       4   \n",
       "10                                       [aggressive]                       9   \n",
       "11                                 [aggressive, epic]                       4   \n",
       "12            [aggressive, angry, driving, energetic]                       8   \n",
       "13                            [aggressive, energetic]                       3   \n",
       "14                                [aggressive, angry]                       7   \n",
       "15                                       [aggressive]                       2   \n",
       "16                                [aggressive, angry]                       8   \n",
       "17                                       [aggressive]                      11   \n",
       "18             [aggressive, intense, epic, uplifting]                       7   \n",
       "19  [aggressive, confrontational, intense, epic, d...                       7   \n",
       "\n",
       "    valence_tags  arousal_tags  dominance_tags  \\\n",
       "0       4.550000      5.273125        5.690625   \n",
       "1       3.710000      5.833000        5.427250   \n",
       "2       3.080000      5.870000        5.490000   \n",
       "3       6.555071      5.537214        5.691357   \n",
       "4       3.771176      5.348235        5.441765   \n",
       "5       2.971389      5.537500        4.726389   \n",
       "6       3.080000      5.870000        5.490000   \n",
       "7       3.807121      5.473939        4.729091   \n",
       "8       3.737211      5.610204        4.626735   \n",
       "9       3.582759      5.757241        5.340000   \n",
       "10      3.259444      5.203056        4.422778   \n",
       "11      5.754167      5.565333        5.836500   \n",
       "12      3.910741      4.915556        4.631852   \n",
       "13      4.564286      5.130000        4.842857   \n",
       "14      3.205476      5.026905        4.584762   \n",
       "15      2.970000      5.936000        5.214000   \n",
       "16      3.285000      5.297222        4.716296   \n",
       "17      5.680882      5.751912        5.930882   \n",
       "18      5.104098      5.476230        5.244672   \n",
       "19      3.838627      4.418725        4.059804   \n",
       "\n",
       "                                    mbid              spotify_id  \\\n",
       "0   cab93def-26c5-4fb0-bedd-26ec4c1619e1  4xkOaSrkexMciUUogZKVTS   \n",
       "1   727a2529-7ee8-4860-aef6-7959884895cb  3fOc9x06lKJBhz435mInlH   \n",
       "2                                    NaN  3Y96xd4Ce0J47dcalLrEC8   \n",
       "3   99dd2c8c-e7c1-413e-8ea4-4497a00ffa18  6tqFC1DIOphJkCwrjVzPmg   \n",
       "4   b9eb3484-5e0e-4690-ab5a-ca91937032a5  5bU4KX47KqtDKKaLM4QCzh   \n",
       "5   49e7b4d2-3772-4301-ba25-3cc46ceb342e  4Q1w4Ryyi8KNxxaFlOQClK   \n",
       "6                                    NaN  49fT6owWuknekShh9utsjv   \n",
       "7   1a826083-5585-445f-a708-415dc90aa050  6DoXuH326aAYEN8CnlLmhP   \n",
       "8   4435982c-b83e-4daa-af2b-9f3430036bb7  104YdibC7VQy78xAVmgRYr   \n",
       "9   fe1cc051-faa7-4953-b331-f6196cd3ddae  5fU6qjmD38P90BMsuqpiuU   \n",
       "10  585398ed-1275-4579-9451-e8dd7db9d59c  1qxkzHlZBXFv5HfyYqJ8cy   \n",
       "11  a3c325ce-fac4-42b9-85da-b3c9e0f243af  2ZIJUwprFZrAaZCRKYfAno   \n",
       "12  3bc2c1a9-43bc-45b2-87fc-4313eb2534fe  6xK3sBdRm99g9T8Ov0gjdF   \n",
       "13  f6cc8417-e590-494c-aba9-e3cbc536442d  62wtttQzoIA9HnNmGVd9Yq   \n",
       "14  8050e7e7-2c7a-4390-bf77-eaedf293c626  3DaC3oRpGInTU0x8DvdSGp   \n",
       "15  23b46286-3b27-431b-8943-9be9d37836f9  0DxYrFOfiFShTbO2XdFpBX   \n",
       "16  b83fe0b7-d40d-4e77-9b2b-606d36e4a391  7EZlzu01NzbR1jWEIDSk5T   \n",
       "17  bf2761fe-8b4d-4cc8-bdea-0ccda7c3fed1  1jRzdY7oUBOhrylNtiMtBD   \n",
       "18  1b49361a-e594-490c-aa60-dde81b235d24  2tdzFXOsJLLI20QdnSqxr1   \n",
       "19  9e387cb2-843f-4db0-a0eb-8ba677dfd93d  1Nvy8JAL3DrO0a6xdgJSvv   \n",
       "\n",
       "                genre  \n",
       "0                 rap  \n",
       "1               metal  \n",
       "2                 rap  \n",
       "3             hip-hop  \n",
       "4               metal  \n",
       "5               metal  \n",
       "6             hip-hop  \n",
       "7            nu metal  \n",
       "8   singer-songwriter  \n",
       "9               metal  \n",
       "10               punk  \n",
       "11         industrial  \n",
       "12              metal  \n",
       "13            hip-hop  \n",
       "14               punk  \n",
       "15          metalcore  \n",
       "16               punk  \n",
       "17            hip-hop  \n",
       "18  alternative metal  \n",
       "19               punk  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# al leer el csv interpreta seeds como string, puede ser arreglado con converters y pd.eval\n",
    "# explode separa las listas en varias filas y problema resuelto\n",
    "# las filas se incrementan a 117825 rows vs 90001 rows original\n",
    "df = pd.read_csv('muse_v3.csv', converters={'seeds': pd.eval})\n",
    "#df = df.explode('seeds')\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solo deja en el dataframe los elementos con 1 seed\n",
    "# mas seeds meten ruido\n",
    "df = df[df['seeds'].map(len) == 1]\n",
    "\n",
    "# solo deja el elemento 0 de seeds\n",
    "df['seeds'] = df['seeds'].map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seeds\n",
      "sleazy         938\n",
      "lazy           835\n",
      "martial        799\n",
      "exotic         799\n",
      "fierce         792\n",
      "              ... \n",
      "outraged         1\n",
      "virile           1\n",
      "motoric          1\n",
      "hymn-like        1\n",
      "translucent      1\n",
      "Name: count, Length: 271, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Mostrar la frecuencia de los datos en la columna 'seeds'\n",
    "frecuencia_seeds = df['seeds'].apply(str).value_counts()\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(frecuencia_seeds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>seeds</th>\n",
       "      <th>valence_tags</th>\n",
       "      <th>arousal_tags</th>\n",
       "      <th>dominance_tags</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eminem</td>\n",
       "      <td>aggressive</td>\n",
       "      <td>4.550000</td>\n",
       "      <td>5.273125</td>\n",
       "      <td>5.690625</td>\n",
       "      <td>rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Metallica</td>\n",
       "      <td>aggressive</td>\n",
       "      <td>3.710000</td>\n",
       "      <td>5.833000</td>\n",
       "      <td>5.427250</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rick Ross</td>\n",
       "      <td>aggressive</td>\n",
       "      <td>3.080000</td>\n",
       "      <td>5.870000</td>\n",
       "      <td>5.490000</td>\n",
       "      <td>rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dope</td>\n",
       "      <td>aggressive</td>\n",
       "      <td>3.771176</td>\n",
       "      <td>5.348235</td>\n",
       "      <td>5.441765</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Drowning Pool</td>\n",
       "      <td>aggressive</td>\n",
       "      <td>2.971389</td>\n",
       "      <td>5.537500</td>\n",
       "      <td>4.726389</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89993</th>\n",
       "      <td>Ethereal Universe</td>\n",
       "      <td>transparent</td>\n",
       "      <td>5.370000</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>ambient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89994</th>\n",
       "      <td>Diana Ross</td>\n",
       "      <td>transparent</td>\n",
       "      <td>5.760000</td>\n",
       "      <td>3.875000</td>\n",
       "      <td>5.005000</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89995</th>\n",
       "      <td>重松俊一</td>\n",
       "      <td>transparent</td>\n",
       "      <td>5.370000</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>video game music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89997</th>\n",
       "      <td>Omar Rodriguez-Lopez</td>\n",
       "      <td>transparent</td>\n",
       "      <td>5.797887</td>\n",
       "      <td>4.132254</td>\n",
       "      <td>5.570563</td>\n",
       "      <td>progressive rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000</th>\n",
       "      <td>Message To Bears</td>\n",
       "      <td>translucent</td>\n",
       "      <td>3.340000</td>\n",
       "      <td>1.405000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>ambient</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65773 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     artist        seeds  valence_tags  arousal_tags  \\\n",
       "0                    Eminem   aggressive      4.550000      5.273125   \n",
       "1                 Metallica   aggressive      3.710000      5.833000   \n",
       "2                 Rick Ross   aggressive      3.080000      5.870000   \n",
       "4                      Dope   aggressive      3.771176      5.348235   \n",
       "5             Drowning Pool   aggressive      2.971389      5.537500   \n",
       "...                     ...          ...           ...           ...   \n",
       "89993     Ethereal Universe  transparent      5.370000      3.450000   \n",
       "89994            Diana Ross  transparent      5.760000      3.875000   \n",
       "89995                  重松俊一  transparent      5.370000      3.450000   \n",
       "89997  Omar Rodriguez-Lopez  transparent      5.797887      4.132254   \n",
       "90000      Message To Bears  translucent      3.340000      1.405000   \n",
       "\n",
       "       dominance_tags             genre  \n",
       "0            5.690625               rap  \n",
       "1            5.427250             metal  \n",
       "2            5.490000               rap  \n",
       "4            5.441765             metal  \n",
       "5            4.726389             metal  \n",
       "...               ...               ...  \n",
       "89993        5.330000           ambient  \n",
       "89994        5.005000               pop  \n",
       "89995        5.330000  video game music  \n",
       "89997        5.570563  progressive rock  \n",
       "90000        3.500000           ambient  \n",
       "\n",
       "[65773 rows x 6 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['lastfm_url', 'mbid', 'spotify_id','track','number_of_emotion_tags'], axis=1, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rap' 'metal' 'hip-hop' 'punk' 'metalcore' 'classic rock' 'rock'\n",
      " 'post-hardcore' 'progressive metal' 'nu metal' 'alternative metal' 'pop'\n",
      " 'thrash metal' 'soundtrack' 'industrial metal' 'post-punk' 'gothic metal'\n",
      " 'death metal' 'alternative rock' 'screamo' 'electronic' 'riot grrrl'\n",
      " 'symphonic metal' 'grunge' 'trip-hop' 'hard rock' 'breakbeat'\n",
      " 'melodic death metal' 'hardcore' 'alternative' 'industrial' 'country'\n",
      " 'indie' 'underground hip hop' 'horrorcore' 'black metal' 'dark electro'\n",
      " 'redneck' 'hardcore punk' 'hip hop' 'math rock' 'deathcore' 'stoner rock'\n",
      " 'russian chanson' 'j-rock' 'post-metal' 'goth' 'bluegrass' 'british'\n",
      " 'christian metal' 'soul' 'experimental' 'industrial rock' 'doom metal'\n",
      " 'grindcore' 'k-pop' 'digital hardcore' 'jazz' 'visual kei' 'electro'\n",
      " 'german' 'mathcore' 'folk metal' 'emo' 'noise rock' 'blues rock'\n",
      " 'minimal techno' 'new wave' 'dance' 'ebm' 'pop punk' 'idm' 'indie rock'\n",
      " 'groove metal' 'christian rock' 'funk' 'crust punk' 'stoner metal'\n",
      " 'acoustic' 'blues' 'oi' 'melodic black metal' 'drum and bass' 'drone'\n",
      " 'd-beat' 'aggrotech' 'electronica' 'symphonic black metal' 'ska'\n",
      " 'dubstep' 'rockabilly' 'house' 'power metal' 'breakcore'\n",
      " 'progressive rock' 'noise' 'psychobilly' 'electronic rock' 'spanish'\n",
      " 'piano' 'folk' 'experimental rock' 'gothic rock' 'horror punk'\n",
      " 'avant-garde' 'post-rock' 'electroclash' 'folk punk' 'techno'\n",
      " 'sludge metal' 'piano rock' 'summer' 'indie pop' 'singer-songwriter'\n",
      " 'grime' 'comedy' 'dark cabaret' 'garage rock' 'depressive black metal'\n",
      " 'britpop' 'poetry' 'cybergrind' 'pop rock' 'powerviolence' 'sad'\n",
      " 'finnish metal' 'shoegaze' 'crunk' 'brazilian rock' 'folk rock' 'french'\n",
      " 'reggae' 'anarcho-punk' 'alternative country' 'northern soul' 'gospel'\n",
      " 'southern rock' 'opera' 'psychedelic rock' 'guitar' 'club' 'trance'\n",
      " 'broadway' 'electropop' 'ritual ambient' 'neoclassical darkwave'\n",
      " 'video game music' 'dark ambient' 'classical' 'hardstyle' 'medieval'\n",
      " 'swedish' 'meditation' 'lo-fi' 'melodic hardcore' 'christian music'\n",
      " 'space rock' 'mantra' 'cyberpunk' 'disco' 'environmental' 'latin' 'dub'\n",
      " 'trap' 'latin pop' 'art pop' 'j-pop' 'irish rock' 'party' 'celtic'\n",
      " 'glam rock' 'lounge' 'synthpop' 'celtic rock' 'deep house' 'choral'\n",
      " 'acid house' 'eurovision' 'viking metal' 'art rock' 'sufi' 'world'\n",
      " 'tribal house' 'uk pop' 'hip pop' 'vogue' 'spoken word'\n",
      " 'contemporary classical' 'water' 'baroque' 'songwriter' 'r&b'\n",
      " 'hard trance' 'power electronics' 'futurepop' 'ambient' 'free jazz'\n",
      " 'industrial techno' 'glitch' 'electro-industrial' 'darkstep' 'mashup'\n",
      " 'j-core' 'power noise' 'japanoise' 'viola' 'j-punk' 'ragga jungle'\n",
      " 'speedcore' 'braindance' 'new rave' 'eurobeat' 'vocaloid'\n",
      " 'psychedelic trance' 'happy' 'happy hardcore' 'gypsy' 'chill' 'nightcore'\n",
      " 'acid trance' 'breaks' 'hardcore techno' 'native american' 'nerdcore'\n",
      " 'acid techno' 'ska punk' 'soft rock' 'drill' 'anime' 'acid jazz'\n",
      " 'soukous' 'jazz funk' 'free improvisation' 'hard techno' 'anthem'\n",
      " 'noise pop' 'slowcore' 'easy listening' 'progressive house' 'violin'\n",
      " 'atmospheric black metal' 'rock en espanol' 'technical death metal'\n",
      " 'progressive black metal' 'synthwave' 'zeuhl' 'vocal trance' 'mpb'\n",
      " 'neofolk' 'cabaret' 'ambient pop' 'psychedelic pop' 'bossa nova' 'motown'\n",
      " 'soundtracks' 'boogie' 'washboard' 'power pop' 'chiptune' 'groove'\n",
      " 'garage rock revival' 'garage' 'russian alternative' 'quiet storm'\n",
      " 'black noise' 'deep ambient' 'minimalism' 'new weird america' 'downtempo'\n",
      " 'jungle' 'avant-garde metal' 'deathrock' 'trip hop' 'wu fam' 'halloween'\n",
      " 'dark jazz' 'teen pop' 'new age' 'dancehall' 'quran' 'chalga'\n",
      " 'a cappella' 'french rock' 'funk carioca' 'electro house' 'world fusion'\n",
      " 'sound collage' 'abstract' 'nu jazz' 'drone metal' 'melodic metal'\n",
      " 'martial industrial' 'shamanic' 'dream pop' 'meme rap' 'witch house'\n",
      " 'funk metal' 'dark wave' 'freak folk' 'harp' 'hauntology' 'russian rock'\n",
      " 'melodic rap' 'funeral doom' 'ambient black metal' 'psychill' 'theme'\n",
      " 'krautrock' 'avant-garde jazz' 'indietronica' 'orchestra' 'accordion'\n",
      " 'lullaby' 'disney' 'steampunk' 'outsider' 'beats' 'chanson'\n",
      " 'alternative pop' 'uk garage' 'turntablism' 'lilith' 'atmosphere'\n",
      " 'klezmer' 'no wave' 'movies' 'swing' 'kids' 'novelty' 'cello' 'calypso'\n",
      " 'goregrind' 'ccm' 'new romantic' 'bossanova' 'boom bap' 'neurofunk'\n",
      " 'tango' 'suomisaundi' 'west coast rap' 'mandolin' 'industrial noise'\n",
      " 'coldwave' 'minimal synth' 'harpsichord' 'psychedelic folk' 'samba'\n",
      " 'neo-psychedelic' 'rock in opposition' 'circus' 'drone ambient' 'rave'\n",
      " 'japanese folk' 'sleep' 'rhythm and blues' 'baroque pop'\n",
      " 'gothic americana' '8-bit' 'children' 'throat singing' 'synth-pop'\n",
      " 'illbient' 'bitpop' 'chill out' 'folktronica' 'sound effects'\n",
      " 'dance-punk' 'drama' 'romance' 'instrumental surf' 'contemporary gospel'\n",
      " 'scottish indie' 'kleinkunst' 'electronicore' 'minimal wave'\n",
      " 'christian dance' 'banjo' 'contemporary folk' 'freestyle' 'brazil'\n",
      " 'liedermacher' 'indie folk' 'football' 'theremin' 'moog' 'country blues'\n",
      " 'vocal jazz' 'post-grunge' 'chillwave' 'dub techno' 'italian pop'\n",
      " 'neue deutsche welle' 'jumpstyle' 'instrumental post-rock'\n",
      " 'experimental ambient' 'space ambient' 'korean pop' 'jazztronica'\n",
      " 'polish black metal' 'norwegian black metal' 'parody' 'usbm'\n",
      " 'swedish metal' 'folk black metal' 'speed metal' 'pirate' 'worship'\n",
      " 'reading' 'sophisti-pop' 'poezja spiewana' 'neo soul' 'girl group'\n",
      " 'chamber pop' 'vaporwave' 'exotica' 'persian pop' 'spa' 'smooth jazz'\n",
      " 'indie hip hop' 'tech house' 'goa trance' 'bolero' 'jazz fusion'\n",
      " 'rock steady' 'bells' 'nu disco' 'progressive trance' 'chillstep' 'yoik'\n",
      " 'ukulele' 'renaissance' 'contemporary jazz' 'dance pop' 'steel guitar'\n",
      " 'koto' 'smooth soul' 'turkish' 'rai' 'schlager' 'instrumental rock'\n",
      " 'classical guitar' 'fado' 'nederpop' 'british invasion' 'underground rap'\n",
      " 'oud' 'detroit techno' 'jam band' 'sitar' 'country rock'\n",
      " 'hamburger schule' 'big band' 'nasheed' 'contemporary vocal jazz'\n",
      " 'jazz rock' 'indian' 'neo-classical' 'indian classical' 'lds' 'yoga'\n",
      " 'reiki' 'zen' 'classical piano' 'field recording' 'spanish pop'\n",
      " 'french hip hop' 'salsa' 'birthday' 'turkish rock' 'flamenco'\n",
      " 'jazz guitar' 'hawaiian' 'ostrock' 'final fantasy' 'experimental pop'\n",
      " 'balearic' 'synth punk' 'bounce' 'kabarett' 'german hip hop' 'ragtime'\n",
      " 'paisley underground' 'accordeon' 'belarusian rock' 'esperanto'\n",
      " 'german rock' 'trova' 'comedy rock' 'queercore' 'tabla' 'bhangra'\n",
      " 'didgeridoo' 'duduk' 'qawwali' 'carnatic' 'bhajan' 'kirtan'\n",
      " 'east coast hip hop' 'dark folk' 'mariachi' 'rock nacional'\n",
      " 'symphonic rock' 'symphonic power metal' 'marching band' 'eurodance'\n",
      " 'jazz rap' 'russian folk' 'glitch pop' 'demoscene' 'latin jazz' 'djent'\n",
      " 'technical brutal death metal' 'new-age' 'darksynth'\n",
      " 'industrial black metal' 'latino' 'belly dance' 'frenchcore' 'drone folk'\n",
      " 'psydub' 'healing' 'russian indie' 'bulgarian folk' 'roots reggae'\n",
      " 'villancicos' 'nueva cancion' 'southern gospel' 'reggaeton' 'rock-n-roll'\n",
      " 'oshare kei' 'minimal-techno' 'europop' 'contemporary country'\n",
      " 'sunshine pop' 'nwobhm' 'brutal death metal' 'french metal'\n",
      " 'library music' 'taiko' 'post-black metal' 'anti-folk' 'liquid funk'\n",
      " 'j-rap' 'iskelma' 'modern rock' 'hands up' 'forro' 'bebop' 'polka'\n",
      " 'dixieland' 'bubblegum pop' 'tropicalia' 'big beat' 'c-pop' 'irish folk'\n",
      " 'israeli rock' 'comic' 'rakugo' 'christian metalcore' 'gypsy punk'\n",
      " 'mambo' 'lovers rock' 'funk rock' 'outlaw country' 'gnawa' 'samba-rock'\n",
      " 'barbershop' 'music hall' 'swamp rock' 'christian pop' 'honky tonk'\n",
      " 'experimental techno' 'experimental electronic' 'shibuya-kei' 'geek rock'\n",
      " 'straight edge' 'space age pop' 'polish rock' 'russian pop' 'c86'\n",
      " 'motivation' 'holidays' 'string quartet' 'alternative hip hop'\n",
      " 'new jack swing' 'cartoon' 'humppa' 'french pop' 'wonky' 'tropical'\n",
      " 'industrial hip hop' 'tech trance' 'cajun' 'neo-pagan' 'hypnosis'\n",
      " 'garage punk' 'fidget house' 'beach music' 'arabic jazz'\n",
      " 'progressive psytrance' 'gypsy jazz' 'ranchera' 'musique concrete' 'wave'\n",
      " 'roots rock' 'dreamgaze' 'latin rock' 'coco' 'erotica' 'lounge house'\n",
      " 'supergroup' 'nintendocore' 'uplifting trance' 'circuit' 'dance rock'\n",
      " 'progressive breaks' 'hard dance' 'tekno' 'bay area indie'\n",
      " 'alternative dance' 'cumbia' 'afrobeat' 'ngoni' 'thai pop' 'early music'\n",
      " 'greek folk' 'full on' 'jaw harp' 'dirty south rap' 'italian folk'\n",
      " 'latin alternative' 'delta blues' 'chicano rap' 'turkish pop' 'focus'\n",
      " 'new orleans rap' 'vocal house' 'pony' 'glam metal' 'sleaze rock'\n",
      " 'glam punk' 'persian traditional' 'french reggae' 'jazz piano'\n",
      " 'atmospheric dnb' 'brass band' 'drill and bass' 'hard house' 'tribute'\n",
      " 'estonian metal' 'avant-rock' 'prank' 'indie-pop' 'dark psytrance'\n",
      " 'szanty' 'death industrial' 'music box' 'glitch hop' 'electro trash'\n",
      " 'balafon' 'ambient trance' 'dark disco' 'broken beat' 'norwegian jazz'\n",
      " 'prog metal' 'bajki' 'jazz metal' 'progressive deathcore'\n",
      " 'progressive post-hardcore' 'shred' 'chaotic hardcore'\n",
      " 'fast melodic punk' 'technical deathcore' 'melodic deathcore'\n",
      " 'melodic metalcore' 'jangle pop' 'study' 'deep techno' 'moombahton'\n",
      " 'pibroch' 'plunderphonics' 'sertanejo' 'skate punk' 'cantautor'\n",
      " 'swamp blues' 'emo rap' 'german punk' 'brega' 'sound' 'fake' 'twee pop'\n",
      " 'atmospheric sludge' 'red dirt' 'k-rock' 'bass music' 'yacht rock'\n",
      " 'retro metal' 'psytech' 'hungarian pop' 'blackgaze' 'electric blues'\n",
      " 'boogaloo' 'c64' 'praise' 'country pop' 'idol' 'disco house'\n",
      " 'german techno' 'american primitive' 'hammond organ' 'ambient techno'\n",
      " 'jazz saxophone' 'future garage' 'flamenco fusion' 'spanish rock' 'enka'\n",
      " 'light music' 'kora' 'british folk' 'cool jazz' 'bachata' 'russian punk'\n",
      " 'ukrainian rock' 'heartland rock' 'cymraeg' 'kwaito' 'magyar' 'carnaval'\n",
      " 'murga' 'emocore' 'boy band' 'opm' 'guqin' 'celtic punk' 'doujin'\n",
      " 'gamelan' 'microhouse' 'byzantine' 'musica andina' 'darbuka'\n",
      " 'orthodox chant' 'navajo' 'italian renaissance' 'finnish pop'\n",
      " 'levenslied' 'pop rap' 'austropop' 'iranian' 'texas country' 'art punk'\n",
      " 'highlife' 'brutal deathcore' 'street punk' 'madchester' 'electro jazz'\n",
      " 'soca' 'j-indie' 'crack rock steady' 'fingerstyle' 'rumba'\n",
      " 'spanish classical' 'karaoke' 'wind quintet' 'merengue' 'minecraft'\n",
      " 'skiffle' 'melancholia' 'merseybeat' 'doo-wop' 'ambient industrial'\n",
      " 'electro swing' 'houston rap' 'noisecore' 'organic ambient' 'tex-mex']\n"
     ]
    }
   ],
   "source": [
    "print(df['genre'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "indie              4970\n",
       "rock               4669\n",
       "electronic         4343\n",
       "pop                3859\n",
       "ambient            2056\n",
       "                   ... \n",
       "orthodox chant        1\n",
       "navajo                1\n",
       "russian chanson       1\n",
       "idol                  1\n",
       "disco house           1\n",
       "Name: count, Length: 775, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre\n",
      "indie              4970\n",
      "rock               4669\n",
      "electronic         4343\n",
      "pop                3859\n",
      "ambient            2056\n",
      "                   ... \n",
      "orthodox chant        1\n",
      "navajo                1\n",
      "russian chanson       1\n",
      "idol                  1\n",
      "disco house           1\n",
      "Name: count, Length: 775, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#obtiene la frecuencia de cada genero y su media\n",
    "frecuencia_genero = df['genre'].value_counts()\n",
    "\n",
    "#imprime los resultados\n",
    "print(frecuencia_genero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El género menos frecuente entre los seleccionados es \"nu jazz\" con 101 frecuencias.\n",
      "Número de géneros con al menos 100 frecuencias: 97\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Obtener la frecuencia de los géneros\n",
    "frecuencia_generos = df['genre'].value_counts()\n",
    "\n",
    "# Seleccionar los géneros que tienen al menos 100 frecuencias\n",
    "generos_minimo_100_frecuencias = frecuencia_generos[frecuencia_generos >= 100]\n",
    "\n",
    "# Graficar la frecuencia de los géneros\n",
    "plt.figure(figsize=(10, 6))\n",
    "generos_minimo_100_frecuencias.plot(kind='bar')\n",
    "plt.title(f'Géneros con al menos 100 Frecuencias')\n",
    "plt.ylabel('Frecuencia')\n",
    "\n",
    "# Ocultar las etiquetas del eje x\n",
    "plt.xticks([])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Encontrar y mostrar el género menos frecuente entre los seleccionados\n",
    "genero_menos_frecuente = generos_minimo_100_frecuencias.idxmin()\n",
    "frecuencia_menos_frecuente = generos_minimo_100_frecuencias.min()\n",
    "print(f'El género menos frecuente entre los seleccionados es \"{genero_menos_frecuente}\" con {frecuencia_menos_frecuente} frecuencias.')\n",
    "\n",
    "# Mostrar la cantidad de géneros seleccionados\n",
    "print(f'Número de géneros con al menos 100 frecuencias: {len(generos_minimo_100_frecuencias)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre\n",
      "world                101\n",
      "sad                  101\n",
      "shoegaze             101\n",
      "singer-songwriter    101\n",
      "ska                  101\n",
      "                    ... \n",
      "anime                101\n",
      "avant-garde          101\n",
      "black metal          101\n",
      "blues                101\n",
      "british              101\n",
      "Name: count, Length: 97, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "conteo_generos = df['genre'].value_counts()\n",
    "\n",
    "# Filtrar solo los géneros con 1000 o más entradas\n",
    "generos_mayor_100 = conteo_generos[conteo_generos >= 100]\n",
    "\n",
    "# Obtener el número mínimo de entradas entre los géneros seleccionados\n",
    "min_entradas = generos_mayor_100.min()\n",
    "\n",
    "# Filtrar el DataFrame original para incluir solo los géneros seleccionados\n",
    "df_filtrado = df[df['genre'].isin(generos_mayor_100.index)]\n",
    "\n",
    "# Ajustar la cantidad de entradas para que todos los géneros tengan la misma cantidad\n",
    "df_ajustado = df_filtrado.groupby('genre').apply(lambda x: x.sample(min_entradas)).reset_index(drop=True)\n",
    "\n",
    "# Verificar el nuevo conteo de entradas por género\n",
    "print(df_ajustado['genre'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>seeds</th>\n",
       "      <th>valence_tags</th>\n",
       "      <th>arousal_tags</th>\n",
       "      <th>dominance_tags</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>José González</td>\n",
       "      <td>mellow</td>\n",
       "      <td>6.587164</td>\n",
       "      <td>3.852537</td>\n",
       "      <td>6.362090</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dave Matthews and Tim Reynolds</td>\n",
       "      <td>cathartic</td>\n",
       "      <td>3.974574</td>\n",
       "      <td>2.163101</td>\n",
       "      <td>3.912403</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neil Halstead</td>\n",
       "      <td>quiet</td>\n",
       "      <td>6.322000</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>5.662000</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suzanne Vega</td>\n",
       "      <td>powerful</td>\n",
       "      <td>5.740725</td>\n",
       "      <td>3.843623</td>\n",
       "      <td>5.335942</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trippy Wicked &amp; the Cosmic Children of the Knight</td>\n",
       "      <td>bleak</td>\n",
       "      <td>2.566667</td>\n",
       "      <td>2.436667</td>\n",
       "      <td>2.603333</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9792</th>\n",
       "      <td>Kalahari Surfers</td>\n",
       "      <td>exotic</td>\n",
       "      <td>7.550000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>5.650000</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9793</th>\n",
       "      <td>Ishta</td>\n",
       "      <td>mystical</td>\n",
       "      <td>5.041683</td>\n",
       "      <td>4.045248</td>\n",
       "      <td>4.694257</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9794</th>\n",
       "      <td>Renato Ventura</td>\n",
       "      <td>philosophical</td>\n",
       "      <td>6.210000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>5.390000</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9795</th>\n",
       "      <td>Issa Bagayogo</td>\n",
       "      <td>exotic</td>\n",
       "      <td>7.550000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>5.650000</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9796</th>\n",
       "      <td>Beats Antique</td>\n",
       "      <td>sensual</td>\n",
       "      <td>6.188571</td>\n",
       "      <td>4.237429</td>\n",
       "      <td>6.059143</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9797 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 artist          seeds  \\\n",
       "0                                         José González         mellow   \n",
       "1                        Dave Matthews and Tim Reynolds      cathartic   \n",
       "2                                         Neil Halstead          quiet   \n",
       "3                                          Suzanne Vega       powerful   \n",
       "4     Trippy Wicked & the Cosmic Children of the Knight          bleak   \n",
       "...                                                 ...            ...   \n",
       "9792                                   Kalahari Surfers         exotic   \n",
       "9793                                              Ishta       mystical   \n",
       "9794                                     Renato Ventura  philosophical   \n",
       "9795                                      Issa Bagayogo         exotic   \n",
       "9796                                      Beats Antique        sensual   \n",
       "\n",
       "      valence_tags  arousal_tags  dominance_tags     genre  \n",
       "0         6.587164      3.852537        6.362090  acoustic  \n",
       "1         3.974574      2.163101        3.912403  acoustic  \n",
       "2         6.322000      3.620000        5.662000  acoustic  \n",
       "3         5.740725      3.843623        5.335942  acoustic  \n",
       "4         2.566667      2.436667        2.603333  acoustic  \n",
       "...            ...           ...             ...       ...  \n",
       "9792      7.550000      6.900000        5.650000     world  \n",
       "9793      5.041683      4.045248        4.694257     world  \n",
       "9794      6.210000      3.500000        5.390000     world  \n",
       "9795      7.550000      6.900000        5.650000     world  \n",
       "9796      6.188571      4.237429        6.059143     world  \n",
       "\n",
       "[9797 rows x 6 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#resetea el indice\n",
    "df_ajustado.reset_index(drop=True, inplace=True)\n",
    "df_ajustado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      valence_tags  arousal_tags  dominance_tags               genre\n",
      "2535      0.472294      0.337706        0.421927           dream pop\n",
      "6585      0.567460      1.310317        0.608730               noise\n",
      "7696      0.570000      1.290000        1.130769                punk\n",
      "6410      0.623571      0.516429        0.675000             new age\n",
      "2348      0.639737      0.706447        0.677368          doom metal\n",
      "1091      0.715714      0.301071        0.750000              celtic\n",
      "6918      0.787500      0.830000        0.787500                 pop\n",
      "2557      0.795745      0.878723        0.842553           dream pop\n",
      "8372      0.845000      0.604205        0.754886            shoegaze\n",
      "523       0.862687      1.413284        0.992090         avant-garde\n",
      "2552      0.864828      0.518966        0.825517           dream pop\n",
      "7462      0.865079      0.707143        0.865873    progressive rock\n",
      "6871      0.880000      2.156522        1.429565                 pop\n",
      "7482      0.911304      0.695652        0.553043    psychedelic rock\n",
      "6141      0.918316      1.540421        0.944211               metal\n",
      "6028      0.924286      0.278571        0.828571          meditation\n",
      "5093      0.944000      1.120000        0.792000          indie rock\n",
      "8683      0.948955      1.047910        1.004776                soul\n",
      "9708      0.973333      1.270000        1.300000               world\n",
      "5967      1.014167      0.570417        1.077083          meditation\n",
      "6784      1.050000      1.745000        1.920000               piano\n",
      "8193      1.050000      1.745000        1.920000                 sad\n",
      "8226      1.050000      1.745000        1.920000                 sad\n",
      "8216      1.050000      1.745000        1.920000                 sad\n",
      "8239      1.050000      1.745000        1.920000                 sad\n",
      "9330      1.050000      1.745000        1.920000              techno\n",
      "7259      1.050000      1.745000        1.920000           post-rock\n",
      "8260      1.050000      1.745000        1.920000                 sad\n",
      "8264      1.050000      1.745000        1.920000                 sad\n",
      "8257      1.050000      1.745000        1.920000                 sad\n",
      "7777      1.050000      1.745000        1.920000                 r&b\n",
      "8234      1.050000      1.745000        1.920000                 sad\n",
      "9171      1.050000      1.745000        1.920000     symphonic metal\n",
      "9225      1.100000      2.260000        1.420000            synthpop\n",
      "7157      1.137297      1.262703        1.070270           post-punk\n",
      "1956      1.144000      0.818000        1.022000        dark ambient\n",
      "1376      1.167333      0.753333        1.094667      christian rock\n",
      "5982      1.175000      2.045000        1.805000          meditation\n",
      "8283      1.192537      0.969254        1.240746            shoegaze\n",
      "7389      1.221980      1.561980        1.541782    progressive rock\n",
      "8988      1.235000      2.795000        2.450000         spoken word\n",
      "6146      1.235667      2.860333        2.056000               metal\n",
      "304       1.236667      1.133333        1.000000             ambient\n",
      "3402      1.246667      1.376667        1.320000         electronica\n",
      "8094      1.246667      1.376667        1.320000                rock\n",
      "3959      1.265000      3.100000        2.055000              german\n",
      "7566      1.275313      1.590313        1.290625    psychedelic rock\n",
      "7501      1.279310      1.724138        1.468966    psychedelic rock\n",
      "4839      1.293103      0.577586        1.091379                 idm\n",
      "6011      1.310000      1.000000        0.795000          meditation\n",
      "6391      1.314000      1.008000        1.158000             new age\n",
      "5525      1.315000      2.930000        1.805000                jazz\n",
      "2415      1.320000      1.060000        1.283333          doom metal\n",
      "3032      1.326337      1.467723        1.625941                 ebm\n",
      "7416      1.335000      2.185000        1.665000    progressive rock\n",
      "1927      1.340000      2.825000        2.200000        dark ambient\n",
      "341       1.370000      0.766000        1.170000             ambient\n",
      "4768      1.375000      2.430000        1.880000                 idm\n",
      "3056      1.375000      2.430000        1.880000                 ebm\n",
      "7572      1.430000      3.125000        2.090000    psychedelic rock\n",
      "8747      1.456667      2.580000        2.583333          soundtrack\n",
      "6034      1.463294      1.077882        1.293882          meditation\n",
      "6530      1.500000      2.100000        2.560000            new wave\n",
      "210       1.500000      2.675000        1.850000    alternative rock\n",
      "8835      1.503254      0.845000        1.331984             spanish\n",
      "6432      1.505172      1.246552        1.629310             new age\n",
      "6284      1.513684      1.010526        1.120000             neofolk\n",
      "2299      1.525000      1.525000        2.895000               disco\n",
      "7550      1.525000      3.120000        1.715000    psychedelic rock\n",
      "7156      1.540000      2.935000        2.745000           post-punk\n",
      "7170      1.542273      3.737045        2.372727           post-punk\n",
      "5879      1.575000      1.660000        1.575000  martial industrial\n",
      "2388      1.575000      1.660000        1.575000          doom metal\n",
      "2365      1.575000      1.660000        1.575000          doom metal\n",
      "2360      1.575000      1.660000        1.575000          doom metal\n",
      "7973      1.575000      2.617500        2.880000                 rap\n",
      "2066      1.575000      1.660000        1.575000        dark electro\n",
      "664       1.575000      1.660000        1.575000         black metal\n",
      "598       1.575000      1.660000        1.575000         avant-garde\n",
      "607       1.583333      3.383333        2.593333         black metal\n",
      "6338      1.586000      2.152000        1.948000             neofolk\n",
      "1719      1.625000      1.450000        2.275000             country\n",
      "8361      1.637143      1.412857        1.692857            shoegaze\n",
      "4055      1.645000      2.000000        2.090000              guitar\n",
      "9433      1.654074      2.976296        1.864074        thrash metal\n",
      "933       1.675424      3.291695        2.932373             britpop\n",
      "1955      1.679762      1.785000        1.720238        dark ambient\n",
      "7004      1.686667      4.133333        2.740000       post-hardcore\n",
      "8716      1.690000      3.065000        1.745000          soundtrack\n",
      "6066      1.690000      3.065000        1.745000               metal\n",
      "5970      1.691321      0.986792        1.487170          meditation\n",
      "7509      1.693333      1.363333        1.536667    psychedelic rock\n",
      "5050      1.703333      3.883333        2.666667          indie rock\n",
      "2547      1.705000      0.857500        1.610000           dream pop\n",
      "3389      1.715000      1.805000        2.720000         electronica\n",
      "3399      1.715000      1.805000        2.720000         electronica\n",
      "5541      1.715000      1.805000        2.720000                jazz\n",
      "3353      1.715000      1.805000        2.720000         electronica\n",
      "753       1.715000      1.805000        2.720000               blues\n",
      "7483      1.715000      1.805000        2.720000    psychedelic rock\n",
      "3419      1.715000      1.805000        2.720000         electronica\n",
      "3433      1.715000      1.805000        2.720000         electronica\n",
      "3407      1.715000      1.805000        2.720000         electronica\n",
      "3408      1.715000      1.805000        2.720000         electronica\n",
      "3338      1.715000      1.805000        2.720000         electronica\n",
      "3432      1.715000      1.805000        2.720000         electronica\n",
      "3362      1.715000      1.805000        2.720000         electronica\n",
      "132       1.715000      1.805000        2.720000         alternative\n",
      "368       1.720000      1.083333        1.850000             ambient\n",
      "533       1.733333      3.523333        2.480000         avant-garde\n",
      "8116      1.737895      1.399211        1.577105                rock\n",
      "508       1.750000      2.880000        1.810000         avant-garde\n",
      "6025      1.759091      1.107955        1.892045          meditation\n",
      "7210      1.760000      2.680000        2.100000           post-rock\n",
      "1152      1.762857      1.547143        2.000000               chill\n",
      "7299      1.765263      1.111842        1.898684   progressive metal\n",
      "7083      1.778000      1.431500        1.613500           post-punk\n",
      "6036      1.782500      0.760000        1.525000          meditation\n",
      "3042      1.783333      2.613333        1.996667                 ebm\n",
      "8246      1.796667      2.496667        2.673333                 sad\n",
      "7703      1.802542      2.829661        1.970339                punk\n",
      "3241      1.806897      1.379310        1.096552          electronic\n",
      "7124      1.810000      2.472500        1.895000           post-punk\n",
      "5861      1.813814      1.300932        1.427712  martial industrial\n",
      "4847      1.813846      1.384615        1.100769                 idm\n",
      "7565      1.815000      2.320000        2.290000    psychedelic rock\n",
      "5662      1.840000      3.893333        2.663333               lo-fi\n",
      "9602      1.855000      2.500000        2.130000            trip-hop\n",
      "7428      1.855000      2.500000        2.130000    progressive rock\n",
      "6746      1.855000      2.500000        2.130000             nu jazz\n",
      "7516      1.860000      1.100000        1.570000    psychedelic rock\n",
      "1920      1.865267      1.719847        1.593893        dark ambient\n",
      "9105      1.870000      2.065000        1.980000     symphonic metal\n",
      "3597      1.870000      2.065000        1.980000        experimental\n",
      "3444      1.870000      2.065000        1.980000                 emo\n",
      "8861      1.870000      2.065000        1.980000             spanish\n",
      "5666      1.870000      2.065000        1.980000               lo-fi\n",
      "460       1.870000      2.065000        1.980000               anime\n",
      "1468      1.870000      2.065000        1.980000        classic rock\n",
      "4985      1.870000      2.065000        1.980000           indie pop\n",
      "6316      1.872035      1.536903        1.924159             neofolk\n",
      "6046      1.873288      0.535616        2.008219          meditation\n",
      "2620      1.880000      1.225000        1.570000           dream pop\n",
      "1724      1.897727      0.798295        1.988636             country\n",
      "1684      1.900000      2.475000        2.585000              comedy\n",
      "7608      1.906667      1.363333        1.703333            psychill\n",
      "2005      1.906667      1.363333        1.703333        dark ambient\n",
      "28        1.906667      1.363333        1.703333            acoustic\n",
      "8230      1.910000      2.710000        2.806667                 sad\n",
      "6325      1.925545      1.376832        1.720198             neofolk\n",
      "1718      1.936667      2.830000        2.700000             country\n",
      "6264      1.946667      2.540000        2.600000             neofolk\n",
      "3100      1.970000      2.180000        2.415000                 ebm\n",
      "2860      1.970000      2.180000        2.415000             dubstep\n",
      "9235      1.970000      2.180000        2.415000            synthpop\n",
      "7592      1.970000      2.180000        2.415000            psychill\n",
      "2643      1.970000      2.180000        2.415000               drone\n",
      "2664      1.970000      2.180000        2.415000               drone\n",
      "9284      1.970000      2.180000        2.415000            synthpop\n",
      "3052      1.970000      2.180000        2.415000                 ebm\n",
      "2330      1.978000      1.804000        2.478000          doom metal\n",
      "3410      1.980000      1.590000        1.925000         electronica\n",
      "8244      1.985000      2.777500        2.910000                 sad\n",
      "323       1.985000      2.585000        2.197500             ambient\n",
      "2354      1.990206      2.185258        2.298660          doom metal\n",
      "6007      1.991698      1.366792        2.135849          meditation\n",
      "6116      1.992500      1.997500        2.170000               metal\n",
      "2208      1.992500      1.997500        2.170000         death metal\n",
      "8908      1.995429      1.652571        2.160000         spoken word\n",
      "2077      1.996667      3.166667        2.693333        dark electro\n",
      "6453      2.000000      0.787500        1.780000             new age\n",
      "6150      2.007259      2.012296        2.186074               metal\n",
      "2390      2.014286      1.595714        1.578571          doom metal\n",
      "7507      2.020000      2.008333        1.885000    psychedelic rock\n",
      "5223      2.043333      4.160000        2.146667          industrial\n",
      "2383      2.053333      2.666667        2.550000          doom metal\n",
      "9039      2.060000      3.397500        2.677500             swedish\n",
      "2357      2.060000      3.143333        2.706667          doom metal\n",
      "2605      2.063333      3.260000        2.513333           dream pop\n",
      "1518      2.065714      1.222857        2.010000           classical\n",
      "2618      2.069333      1.368000        1.626667           dream pop\n",
      "7432      2.077037      1.531852        1.982222    progressive rock\n",
      "8459      2.078214      5.092857        3.376071   singer-songwriter\n",
      "2362      2.085000      2.972500        2.935000          doom metal\n",
      "2392      2.089604      2.202376        2.089604          doom metal\n",
      "8318      2.093929      2.456429        2.490714            shoegaze\n",
      "8898      2.096753      4.032753        3.201974         spoken word\n",
      "2666      2.105000      2.300000        2.625000               drone\n",
      "7172      2.105000      2.855000        2.675000           post-rock\n",
      "2372      2.110833      2.180595        2.162500          doom metal\n",
      "5003      2.120000      3.176667        3.056667           indie pop\n",
      "6041      2.133143      1.366286        1.939429          meditation\n",
      "60        2.136667      2.833333        2.430000            acoustic\n",
      "6024      2.138824      1.258676        2.001176          meditation\n",
      "8939      2.142857      4.441429        3.381429         spoken word\n",
      "2302      2.143333      1.450000        1.940000               disco\n",
      "908       2.150000      2.276000        2.720000             british\n",
      "8976      2.152308      5.499316        4.346068         spoken word\n",
      "1055      2.153333      1.803333        2.316667              celtic\n",
      "2582      2.155636      1.652182        1.980727           dream pop\n",
      "7951      2.160000      1.775000        2.585000                 rap\n",
      "7025      2.166667      4.106667        3.290000       post-hardcore\n",
      "6151      2.166667      4.106667        3.290000               metal\n",
      "6346      2.175000      1.515000        1.978500             neofolk\n",
      "311       2.178919      1.320541        1.880000             ambient\n",
      "3702      2.182000      2.374000        2.672000                folk\n",
      "8930      2.190000      2.760000        2.795000         spoken word\n",
      "8986      2.190000      2.760000        2.795000         spoken word\n",
      "3334      2.200000      3.000000        2.240000         electronica\n",
      "8692      2.200000      3.000000        2.240000          soundtrack\n",
      "3274      2.200000      3.000000        2.240000          electronic\n",
      "2046      2.200000      3.000000        2.240000        dark electro\n",
      "2472      2.200000      3.000000        2.240000           downtempo\n",
      "4097      2.200000      3.000000        2.240000              guitar\n",
      "4827      2.210000      1.303333        2.133333                 idm\n",
      "145       2.211683      1.696634        1.949109         alternative\n",
      "7447      2.213421      1.101579        2.001316    progressive rock\n",
      "2075      2.223333      2.893333        2.450000        dark electro\n",
      "6643      2.225000      2.430000        1.780000               noise\n",
      "3214      2.225000      2.430000        1.780000             electro\n",
      "8951      2.242857      4.310000        3.238571         spoken word\n",
      "8965      2.242857      4.310000        3.238571         spoken word\n",
      "8922      2.242857      4.310000        3.238571         spoken word\n",
      "8962      2.242857      4.310000        3.238571         spoken word\n",
      "6260      2.245000      6.230000        4.290000           metalcore\n",
      "3529      2.250000      3.150000        3.840000                 emo\n",
      "7460      2.253858      2.450551        2.734488    progressive rock\n",
      "8932      2.254000      4.321333        3.301333         spoken word\n",
      "6519      2.255319      1.324255        2.086809            new wave\n",
      "1444      2.260682      2.379318        3.585455        classic rock\n",
      "7583      2.261932      1.762500        2.215909            psychill\n",
      "7352      2.262500      4.112500        4.027500   progressive metal\n",
      "8944      2.263750      4.331250        3.356250         spoken word\n",
      "8904      2.263750      4.331250        3.356250         spoken word\n",
      "1500      2.275347      2.394752        3.608713        classic rock\n",
      "6588      2.292000      3.354000        3.152000               noise\n",
      "6032      2.296667      0.556667        2.480000          meditation\n",
      "3480      2.315000      4.845000        3.975000                 emo\n",
      "2001      2.327586      4.106897        3.086207        dark ambient\n",
      "2912      2.336667      1.703333        2.060000             dubstep\n",
      "5104      2.338286      1.176000        2.208000          indie rock\n",
      "2395      2.347059      2.473725        2.347059          doom metal\n",
      "7699      2.350000      5.390000        4.360000                punk\n",
      "9438      2.350000      5.390000        4.360000        thrash metal\n",
      "1550      2.352000      3.158000        3.168000           classical\n",
      "7679      2.353929      4.269107        2.430536                punk\n",
      "2700      2.363333      2.560000        2.660000               drone\n",
      "8279      2.367500      3.065000        3.095000                 sad\n",
      "5202      2.370000      3.291250        2.421250          industrial\n",
      "638       2.375000      5.075000        3.890000         black metal\n",
      "2413      2.376471      2.045882        2.534706          doom metal\n",
      "8185      2.385000      3.930000        3.585000                 sad\n",
      "8265      2.385000      3.930000        3.585000                 sad\n",
      "4953      2.385000      3.930000        3.585000           indie pop\n",
      "5005      2.385000      3.930000        3.585000           indie pop\n",
      "8796      2.385000      3.930000        3.585000             spanish\n",
      "4960      2.385000      3.930000        3.585000           indie pop\n",
      "8980      2.393333      2.526667        2.816667         spoken word\n",
      "1963      2.395000      3.725000        2.800000        dark ambient\n",
      "7316      2.406667      2.006667        2.096667   progressive metal\n",
      "700       2.410000      4.480000        4.180000         black metal\n",
      "705       2.410000      4.480000        4.180000         black metal\n",
      "673       2.410000      4.480000        4.180000         black metal\n",
      "2406      2.410000      4.480000        4.180000          doom metal\n",
      "4075      2.410000      4.480000        4.180000              guitar\n",
      "4434      2.410000      5.435000        3.475000            hardcore\n",
      "699       2.410000      4.480000        4.180000         black metal\n",
      "609       2.410000      4.480000        4.180000         black metal\n",
      "6148      2.410000      4.480000        4.180000               metal\n",
      "9402      2.410000      4.480000        4.180000        thrash metal\n",
      "676       2.410000      4.480000        4.180000         black metal\n",
      "616       2.410000      4.480000        4.180000         black metal\n",
      "695       2.410000      4.480000        4.180000         black metal\n",
      "680       2.410000      4.480000        4.180000         black metal\n",
      "5199      2.410000      4.480000        4.180000          industrial\n",
      "2042      2.412000      4.168000        3.464000        dark electro\n",
      "3448      2.412212      4.241751        3.247465                 emo\n",
      "9693      2.420000      2.246667        3.130000            trip-hop\n",
      "6656      2.423333      4.738333        2.953333               noise\n",
      "3847      2.425000      2.885000        2.890000                funk\n",
      "8765      2.445000      4.262500        2.775000          soundtrack\n",
      "9511      2.446667      2.496667        2.340000              trance\n",
      "6823      2.466471      2.023882        2.373059               piano\n",
      "8269      2.480606      4.226061        3.826364                 sad\n",
      "8199      2.485446      2.882376        3.750792                 sad\n",
      "180       2.487143      2.767143        2.948571         alternative\n",
      "8137      2.493333      2.753333        2.640000                rock\n",
      "6356      2.498957      2.042696        2.540870             neofolk\n",
      "688       2.500000      2.640000        3.120000         black metal\n",
      "7027      2.500000      5.895000        4.505000       post-hardcore\n",
      "7504      2.500870      1.669565        1.850435    psychedelic rock\n",
      "5702      2.506667      1.633333        2.093333               lo-fi\n",
      "913       2.506667      2.626667        2.766667             britpop\n",
      "7702      2.508824      5.747353        4.160294                punk\n",
      "5315      2.510000      4.230000        3.470000               j-pop\n",
      "4065      2.513333      3.323333        3.433333              guitar\n",
      "1494      2.513333      3.323333        3.433333        classic rock\n",
      "3515      2.516348      5.026877        3.814761                 emo\n",
      "8136      2.520000      5.050000        4.290000                rock\n",
      "7468      2.520000      5.050000        4.290000    progressive rock\n",
      "3084      2.520000      5.050000        4.290000                 ebm\n",
      "7691      2.520000      6.110000        4.453333                punk\n",
      "5189      2.520000      5.050000        4.290000          industrial\n",
      "2038      2.520000      5.050000        4.290000        dark electro\n",
      "7144      2.520000      6.110000        4.453333           post-punk\n",
      "5584      2.527442      4.980988        4.036105               k-pop\n",
      "8573      2.530000      6.200000        4.110000                 ska\n",
      "4374      2.530000      6.200000        4.110000            hardcore\n",
      "4375      2.530000      6.200000        4.110000            hardcore\n",
      "6098      2.530000      6.200000        4.110000               metal\n",
      "7041      2.530000      6.200000        4.110000       post-hardcore\n",
      "7133      2.530000      6.200000        4.110000           post-punk\n",
      "7761      2.530000      6.200000        4.110000                punk\n",
      "3508      2.530000      6.200000        4.110000                 emo\n",
      "9412      2.530000      6.200000        4.110000        thrash metal\n",
      "7774      2.530000      6.200000        4.110000                punk\n",
      "8322      2.530000      6.200000        4.110000            shoegaze\n",
      "9445      2.530000      6.200000        4.110000        thrash metal\n",
      "4347      2.530000      6.200000        4.110000            hardcore\n",
      "8553      2.530000      6.200000        4.110000                 ska\n",
      "3501      2.530000      6.200000        4.110000                 emo\n",
      "534       2.530000      6.200000        4.110000         avant-garde\n",
      "9410      2.530000      6.200000        4.110000        thrash metal\n",
      "4367      2.530000      6.200000        4.110000            hardcore\n",
      "9470      2.530000      6.200000        4.110000        thrash metal\n",
      "4453      2.530000      6.200000        4.110000             hip hop\n",
      "6531      2.530000      6.200000        4.110000            new wave\n",
      "4428      2.530000      6.200000        4.110000            hardcore\n",
      "6170      2.530000      6.200000        4.110000           metalcore\n",
      "115       2.530000      6.200000        4.110000         alternative\n",
      "2186      2.530000      6.200000        4.110000         death metal\n",
      "6166      2.530000      6.200000        4.110000           metalcore\n",
      "9482      2.530000      6.200000        4.110000        thrash metal\n",
      "9483      2.530000      6.200000        4.110000        thrash metal\n",
      "4320      2.530000      6.200000        4.110000           hard rock\n",
      "4395      2.530000      6.200000        4.110000            hardcore\n",
      "6975      2.530000      6.200000        4.110000       post-hardcore\n",
      "4446      2.530000      6.200000        4.110000             hip hop\n",
      "8580      2.530000      6.200000        4.110000                 ska\n",
      "4364      2.530000      6.200000        4.110000            hardcore\n",
      "4403      2.530000      6.200000        4.110000            hardcore\n",
      "7706      2.530000      6.200000        4.110000                punk\n",
      "9400      2.530000      6.200000        4.110000        thrash metal\n",
      "7753      2.530000      6.200000        4.110000                punk\n",
      "9373      2.530000      6.200000        4.110000              techno\n",
      "7747      2.530000      6.200000        4.110000                punk\n",
      "7680      2.530000      6.200000        4.110000                punk\n",
      "7944      2.530000      6.200000        4.110000                 rap\n",
      "5636      2.534253      5.060390        4.060714               k-pop\n",
      "1012      2.535889      3.219333        2.709111              celtic\n",
      "419       2.536667      3.430000        2.906667               anime\n",
      "1945      2.540000      2.045000        2.305000        dark ambient\n",
      "6339      2.540000      2.045000        2.305000             neofolk\n",
      "8353      2.540000      2.045000        2.305000            shoegaze\n",
      "6294      2.540000      2.045000        2.305000             neofolk\n",
      "7527      2.540000      2.045000        2.305000    psychedelic rock\n",
      "2709      2.540000      2.045000        2.305000               drone\n",
      "7194      2.540000      2.045000        2.305000           post-rock\n",
      "9322      2.540000      2.045000        2.305000              techno\n",
      "5167      2.540000      2.045000        2.305000          industrial\n",
      "524       2.540000      2.045000        2.305000         avant-garde\n",
      "5250      2.540000      2.045000        2.305000          industrial\n",
      "8391      2.540000      2.045000        2.305000   singer-songwriter\n",
      "7130      2.540000      2.045000        2.305000           post-punk\n",
      "3593      2.540000      2.045000        2.305000        experimental\n",
      "2396      2.540000      2.045000        2.305000          doom metal\n",
      "1426      2.542931      2.676379        4.033103        classic rock\n",
      "5743      2.545000      2.105000        2.260000               lo-fi\n",
      "9269      2.545000      2.105000        2.260000            synthpop\n",
      "9604      2.547557      2.107710        2.393053            trip-hop\n",
      "6244      2.550000      6.145000        4.000000           metalcore\n",
      "8743      2.550000      2.045000        3.220000          soundtrack\n",
      "8609      2.550000      2.045000        3.220000                soul\n",
      "9128      2.555000      2.320000        2.650000     symphonic metal\n",
      "428       2.557681      4.859275        3.864783               anime\n",
      "8477      2.562500      1.760000        2.970000   singer-songwriter\n",
      "6110      2.563333      6.086667        3.943333               metal\n",
      "4         2.566667      2.436667        2.603333            acoustic\n",
      "447       2.574737      4.900526        3.886316               anime\n",
      "440       2.577043      4.895652        3.887565               anime\n",
      "7506      2.577647      1.747941        2.242059    psychedelic rock\n",
      "2492      2.580000      1.625000        2.775000           downtempo\n",
      "4769      2.580000      1.625000        2.775000                 idm\n",
      "9781      2.580000      1.625000        2.775000               world\n",
      "2545      2.580000      1.625000        2.775000           dream pop\n",
      "3367      2.580000      1.625000        2.775000         electronica\n",
      "7587      2.580000      1.625000        2.775000            psychill\n",
      "3856      2.580000      1.625000        2.775000                funk\n",
      "4444      2.580000      1.625000        2.775000             hip hop\n",
      "8576      2.580000      1.625000        2.775000                 ska\n",
      "1137      2.580000      1.625000        2.775000               chill\n",
      "1148      2.580000      1.625000        2.775000               chill\n",
      "4519      2.580000      1.625000        2.775000             hip hop\n",
      "8489      2.580000      1.625000        2.775000                 ska\n",
      "8018      2.580000      1.625000        2.775000              reggae\n",
      "1177      2.580000      1.625000        2.775000               chill\n",
      "6013      2.580000      1.625000        2.775000          meditation\n",
      "5479      2.580000      1.625000        2.775000                jazz\n",
      "6363      2.580000      1.625000        2.775000             new age\n",
      "6390      2.580000      1.625000        2.775000             new age\n",
      "8061      2.580000      1.625000        2.775000              reggae\n",
      "8036      2.580000      1.625000        2.775000              reggae\n",
      "1130      2.580000      1.625000        2.775000               chill\n",
      "1180      2.580000      1.625000        2.775000               chill\n",
      "6722      2.580000      1.625000        2.775000             nu jazz\n",
      "9740      2.580000      1.625000        2.775000               world\n",
      "466       2.580760      4.740866        3.744590               anime\n",
      "8248      2.581386      2.705644        3.680099                 sad\n",
      "7771      2.582500      3.702500        3.340000                punk\n",
      "7728      2.582500      3.702500        3.340000                punk\n",
      "7716      2.582500      3.702500        3.340000                punk\n",
      "568       2.585000      3.295000        2.385000         avant-garde\n",
      "5248      2.585000      3.295000        2.385000          industrial\n",
      "4869      2.585000      3.295000        2.385000               indie\n",
      "488       2.587324      4.798901        3.914789               anime\n",
      "3445      2.589875      4.822693        3.913304                 emo\n",
      "9489      2.593333      4.043333        2.656667        thrash metal\n",
      "1419      2.595937      1.958125        2.370469        classic rock\n",
      "2361      2.598966      4.351034        4.167586          doom metal\n",
      "2149      2.602692      4.569231        4.250000         death metal\n",
      "5641      2.605581      4.874767        3.953081               k-pop\n",
      "5587      2.605581      4.874767        3.953081               k-pop\n",
      "5565      2.605695      4.874508        3.953119               k-pop\n",
      "1976      2.606667      2.526667        2.983333        dark ambient\n",
      "8213      2.606667      2.526667        2.983333                 sad\n",
      "624       2.616364      4.958182        3.983636         black metal\n",
      "3328      2.620000      2.000000        1.590000          electronic\n",
      "9562      2.620000      2.000000        1.590000              trance\n",
      "4698      2.620000      2.000000        1.590000               house\n",
      "7496      2.620000      2.000000        1.590000    psychedelic rock\n",
      "9501      2.620000      2.000000        1.590000              trance\n",
      "8365      2.625000      3.405000        3.495000            shoegaze\n",
      "8108      2.625000      6.185000        4.450000                rock\n",
      "648       2.625000      1.865000        1.970000         black metal\n",
      "6516      2.625000      3.405000        3.495000            new wave\n",
      "6558      2.625000      3.405000        3.495000            new wave\n",
      "8270      2.625000      3.405000        3.495000                 sad\n",
      "2636      2.625000      1.865000        1.970000               drone\n",
      "7984      2.625000      1.865000        1.970000              reggae\n",
      "3332      2.625000      1.865000        1.970000          electronic\n",
      "782       2.625446      3.199307        4.287030               blues\n",
      "9424      2.630000      6.160000        4.365000        thrash metal\n",
      "513       2.640000      5.230000        4.025000         avant-garde\n",
      "5249      2.640000      5.975000        4.420000          industrial\n",
      "1584      2.645000      1.740000        2.805000           classical\n",
      "118       2.645000      4.245000        3.525000         alternative\n",
      "815       2.650000      2.680000        3.475000             british\n",
      "9710      2.650000      1.960000        2.921250               world\n",
      "2366      2.650000      2.584231        2.785577          doom metal\n",
      "4887      2.655000      1.793750        2.163750               indie\n",
      "1007      2.655897      3.326923        3.843846             britpop\n",
      "2123      2.656667      2.663333        2.893333         death metal\n",
      "2151      2.656667      2.663333        2.893333         death metal\n",
      "2221      2.656667      2.663333        2.893333         death metal\n",
      "9461      2.656667      2.663333        2.893333        thrash metal\n",
      "2146      2.656667      2.663333        2.893333         death metal\n",
      "2154      2.656667      2.663333        2.893333         death metal\n",
      "2198      2.656667      2.663333        2.893333         death metal\n",
      "2210      2.656667      2.663333        2.893333         death metal\n",
      "2183      2.656667      2.663333        2.893333         death metal\n",
      "2122      2.656667      2.663333        2.893333         death metal\n",
      "2158      2.656667      2.663333        2.893333         death metal\n",
      "2150      2.656667      2.663333        2.893333         death metal\n",
      "2164      2.656667      2.663333        2.893333         death metal\n",
      "2209      2.656667      2.663333        2.893333         death metal\n",
      "2159      2.656667      2.663333        2.893333         death metal\n",
      "2172      2.656667      2.663333        2.893333         death metal\n",
      "2161      2.656667      2.663333        2.893333         death metal\n",
      "3458      2.658183      4.769850        3.730288                 emo\n",
      "8380      2.658790      1.434076        2.347771            shoegaze\n",
      "5558      2.660351      4.911228        3.836316               k-pop\n",
      "8756      2.662222      4.455556        2.964444          soundtrack\n",
      "2537      2.666429      1.828929        2.287500           dream pop\n",
      "5689      2.666667      1.786667        1.973333               lo-fi\n",
      "7062      2.666667      1.786667        1.973333       post-hardcore\n",
      "5683      2.666667      1.786667        1.973333               lo-fi\n",
      "6864      2.670000      4.370000        3.330000               piano\n",
      "9033      2.670000      4.370000        3.330000             swedish\n",
      "9196      2.670000      4.370000        3.330000            synthpop\n",
      "3533      2.670000      4.370000        3.330000                 emo\n",
      "5294      2.670000      4.370000        3.330000               j-pop\n",
      "8001      2.670000      4.370000        3.330000              reggae\n",
      "3000      2.670000      4.370000        3.330000      easy listening\n",
      "5300      2.670000      4.370000        3.330000               j-pop\n",
      "818       2.670000      4.370000        3.330000             british\n",
      "3519      2.670000      4.370000        3.330000                 emo\n",
      "7793      2.670000      4.370000        3.330000                 r&b\n",
      "8408      2.670000      4.370000        3.330000   singer-songwriter\n",
      "8011      2.670000      4.370000        3.330000              reggae\n",
      "8002      2.670000      4.370000        3.330000              reggae\n",
      "6825      2.670000      4.370000        3.330000               piano\n",
      "5638      2.670000      4.370000        3.330000               k-pop\n",
      "8923      2.670000      4.370000        3.330000         spoken word\n",
      "5622      2.670000      4.370000        3.330000               k-pop\n",
      "7357      2.670000      4.370000        3.330000   progressive metal\n",
      "4002      2.670000      4.370000        3.330000              german\n",
      "5141      2.670000      4.370000        3.330000          indie rock\n",
      "482       2.670000      1.525000        3.132500               anime\n",
      "5454      2.670000      4.370000        3.330000                jazz\n",
      "8478      2.670000      4.370000        3.330000   singer-songwriter\n"
     ]
    }
   ],
   "source": [
    "a = df_ajustado[['valence_tags','arousal_tags', 'dominance_tags','genre']].sort_values(by=['valence_tags']).head(500)\n",
    "print(a.to_string())\n",
    "df_ajustado.to_csv('df_ajustado.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "#pasa todas las columnas a numeros\n",
    "# df_ajustado = df_ajustado.drop(['seeds', 'artist', 'number_of_emotion_tags'], axis=1).reset_index(drop=True)\n",
    "df_ajustado = df_ajustado.drop(['artist'], axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seeds</th>\n",
       "      <th>valence_tags</th>\n",
       "      <th>arousal_tags</th>\n",
       "      <th>dominance_tags</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mellow</td>\n",
       "      <td>6.587164</td>\n",
       "      <td>3.852537</td>\n",
       "      <td>6.362090</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cathartic</td>\n",
       "      <td>3.974574</td>\n",
       "      <td>2.163101</td>\n",
       "      <td>3.912403</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quiet</td>\n",
       "      <td>6.322000</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>5.662000</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>powerful</td>\n",
       "      <td>5.740725</td>\n",
       "      <td>3.843623</td>\n",
       "      <td>5.335942</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bleak</td>\n",
       "      <td>2.566667</td>\n",
       "      <td>2.436667</td>\n",
       "      <td>2.603333</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9792</th>\n",
       "      <td>exotic</td>\n",
       "      <td>7.550000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>5.650000</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9793</th>\n",
       "      <td>mystical</td>\n",
       "      <td>5.041683</td>\n",
       "      <td>4.045248</td>\n",
       "      <td>4.694257</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9794</th>\n",
       "      <td>philosophical</td>\n",
       "      <td>6.210000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>5.390000</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9795</th>\n",
       "      <td>exotic</td>\n",
       "      <td>7.550000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>5.650000</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9796</th>\n",
       "      <td>sensual</td>\n",
       "      <td>6.188571</td>\n",
       "      <td>4.237429</td>\n",
       "      <td>6.059143</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9797 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              seeds  valence_tags  arousal_tags  dominance_tags     genre\n",
       "0            mellow      6.587164      3.852537        6.362090  acoustic\n",
       "1         cathartic      3.974574      2.163101        3.912403  acoustic\n",
       "2             quiet      6.322000      3.620000        5.662000  acoustic\n",
       "3          powerful      5.740725      3.843623        5.335942  acoustic\n",
       "4             bleak      2.566667      2.436667        2.603333  acoustic\n",
       "...             ...           ...           ...             ...       ...\n",
       "9792         exotic      7.550000      6.900000        5.650000     world\n",
       "9793       mystical      5.041683      4.045248        4.694257     world\n",
       "9794  philosophical      6.210000      3.500000        5.390000     world\n",
       "9795         exotic      7.550000      6.900000        5.650000     world\n",
       "9796        sensual      6.188571      4.237429        6.059143     world\n",
       "\n",
       "[9797 rows x 5 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "# for column in df_ajustado.columns:\n",
    "#     df_ajustado[column] = le.fit_transform(df_ajustado[column])\n",
    "# df_ajustado['seeds'] = le.fit_transform(df_ajustado['seeds'])\n",
    "df_ajustado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ajustado['genre'] = le.fit_transform(df_ajustado['genre'])\n",
    "df_ajustado['seeds'] = le.fit_transform(df_ajustado['seeds'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datos todas las columnas menos valence_tags\n",
    "def get_datos(categoria):\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    etiquetas = df_ajustado[categoria]\n",
    "    datos = df_ajustado.drop([categoria], axis=1)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(datos, etiquetas, train_size=0.8, shuffle=True)\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    # Convertir las etiquetas a one-hot encoding\n",
    "    y_train = tf.keras.utils.to_categorical(y_train)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "def get_moddelo(x_train, x_test, y_train, y_test):\n",
    "    # Crear el modelo\n",
    "    num_epochs = 2000\n",
    "    learning_rate = 5e-3\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(x_train.shape[1],)))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "    #model.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=SGD(learning_rate=learning_rate, momentum=0.8),metrics=['accuracy'])\n",
    "    model_fit = model.fit(x_train, y_train, epochs=num_epochs, validation_data=(x_test, y_test), batch_size=32)\n",
    "    return model, model_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from matplotlib import pyplot\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(x_train, x_test, y_train, y_test):\n",
    "    model = DecisionTreeClassifier()\n",
    "    model = model.fit(x_train, y_train)\n",
    "    return model.score(x_test, y_test)\n",
    "    \n",
    "\n",
    "def random_forest(x_train, x_test, y_train, y_test):\n",
    "    model = RandomForestClassifier(n_estimators=256)\n",
    "    model.fit(x_train, y_train)\n",
    "    return model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_graficos(model, model_fit, x_test, y_test):\n",
    "    #epoch - perdida\n",
    "    plt.figure()\n",
    "    plt.plot(model_fit.epoch, model_fit.history['loss'])\n",
    "    plt.xlabel(\"Perdida\")\n",
    "    plt.ylabel(\"Epoch\")\n",
    "    plt.title(\"Entrenamiento\")\n",
    "    plt.show()\n",
    "\n",
    "    #epoch - acierto\n",
    "    plt.figure()\n",
    "    plt.plot(model_fit.epoch, model_fit.history['accuracy'])\n",
    "    plt.xlabel(\"Accuracy\")\n",
    "    plt.ylabel(\"Epoch\")\n",
    "    plt.title(\"Entrenamiento\")\n",
    "    plt.show()\n",
    "\n",
    "    #imprime matriz confusion\n",
    "    # y_pred = model.predict(x_test)\n",
    "    # y_pred = np.argmax(y_pred, axis=1)\n",
    "    # y_test = np.argmax(y_test, axis=1)\n",
    "    # cm = confusion_matrix(y_test, y_pred)\n",
    "    # disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "    # disp.plot()\n",
    "\n",
    "# #ver que pasa con cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_test, y_train, y_test = get_datos(\"genre\")\n",
    "# genre_model, genre_model_fit = get_moddelo(x_train, x_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'{genre_model.evaluate(x_test, y_test)=}')\n",
    "# print(f'{decision_tree(x_train, x_test, y_train, y_test)=}')\n",
    "# print(f'{random_forest(x_train, x_test, y_train, y_test)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrar_graficos(genre_model, genre_model_fit, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "245/245 [==============================] - 0s 959us/step - loss: 1.8584 - accuracy: 0.2905 - val_loss: 1.6174 - val_accuracy: 0.3765\n",
      "Epoch 2/2000\n",
      "245/245 [==============================] - 0s 657us/step - loss: 1.5405 - accuracy: 0.3683 - val_loss: 1.3824 - val_accuracy: 0.4582\n",
      "Epoch 3/2000\n",
      "245/245 [==============================] - 0s 659us/step - loss: 1.3835 - accuracy: 0.4281 - val_loss: 1.2522 - val_accuracy: 0.4852\n",
      "Epoch 4/2000\n",
      "245/245 [==============================] - 0s 669us/step - loss: 1.3001 - accuracy: 0.4629 - val_loss: 1.1787 - val_accuracy: 0.5240\n",
      "Epoch 5/2000\n",
      "245/245 [==============================] - 0s 718us/step - loss: 1.2489 - accuracy: 0.4662 - val_loss: 1.1360 - val_accuracy: 0.5296\n",
      "Epoch 6/2000\n",
      "245/245 [==============================] - 0s 656us/step - loss: 1.2133 - accuracy: 0.4841 - val_loss: 1.1025 - val_accuracy: 0.5286\n",
      "Epoch 7/2000\n",
      "245/245 [==============================] - 0s 670us/step - loss: 1.1909 - accuracy: 0.4899 - val_loss: 1.0772 - val_accuracy: 0.5423\n",
      "Epoch 8/2000\n",
      "245/245 [==============================] - 0s 662us/step - loss: 1.1743 - accuracy: 0.4925 - val_loss: 1.0594 - val_accuracy: 0.5541\n",
      "Epoch 9/2000\n",
      "245/245 [==============================] - 0s 657us/step - loss: 1.1497 - accuracy: 0.5043 - val_loss: 1.0422 - val_accuracy: 0.5526\n",
      "Epoch 10/2000\n",
      "245/245 [==============================] - 0s 685us/step - loss: 1.1314 - accuracy: 0.5167 - val_loss: 1.0341 - val_accuracy: 0.5556\n",
      "Epoch 11/2000\n",
      "245/245 [==============================] - 0s 646us/step - loss: 1.1192 - accuracy: 0.5169 - val_loss: 1.0214 - val_accuracy: 0.5648\n",
      "Epoch 12/2000\n",
      "245/245 [==============================] - 0s 645us/step - loss: 1.1063 - accuracy: 0.5192 - val_loss: 1.0155 - val_accuracy: 0.5612\n",
      "Epoch 13/2000\n",
      "245/245 [==============================] - 0s 645us/step - loss: 1.1065 - accuracy: 0.5230 - val_loss: 1.0057 - val_accuracy: 0.5724\n",
      "Epoch 14/2000\n",
      "245/245 [==============================] - 0s 642us/step - loss: 1.0860 - accuracy: 0.5309 - val_loss: 0.9986 - val_accuracy: 0.5781\n",
      "Epoch 15/2000\n",
      "245/245 [==============================] - 0s 637us/step - loss: 1.0831 - accuracy: 0.5299 - val_loss: 0.9924 - val_accuracy: 0.5714\n",
      "Epoch 16/2000\n",
      "245/245 [==============================] - 0s 660us/step - loss: 1.0816 - accuracy: 0.5366 - val_loss: 0.9897 - val_accuracy: 0.5776\n",
      "Epoch 17/2000\n",
      "245/245 [==============================] - 0s 671us/step - loss: 1.0731 - accuracy: 0.5298 - val_loss: 0.9831 - val_accuracy: 0.5679\n",
      "Epoch 18/2000\n",
      "245/245 [==============================] - 0s 653us/step - loss: 1.0706 - accuracy: 0.5369 - val_loss: 0.9789 - val_accuracy: 0.5770\n",
      "Epoch 19/2000\n",
      "245/245 [==============================] - 0s 648us/step - loss: 1.0530 - accuracy: 0.5549 - val_loss: 0.9734 - val_accuracy: 0.5755\n",
      "Epoch 20/2000\n",
      "245/245 [==============================] - 0s 654us/step - loss: 1.0520 - accuracy: 0.5473 - val_loss: 0.9679 - val_accuracy: 0.5857\n",
      "Epoch 21/2000\n",
      "245/245 [==============================] - 0s 638us/step - loss: 1.0486 - accuracy: 0.5457 - val_loss: 0.9636 - val_accuracy: 0.5852\n",
      "Epoch 22/2000\n",
      "245/245 [==============================] - 0s 652us/step - loss: 1.0446 - accuracy: 0.5445 - val_loss: 0.9619 - val_accuracy: 0.5842\n",
      "Epoch 23/2000\n",
      "245/245 [==============================] - 0s 651us/step - loss: 1.0372 - accuracy: 0.5552 - val_loss: 0.9602 - val_accuracy: 0.5852\n",
      "Epoch 24/2000\n",
      "245/245 [==============================] - 0s 669us/step - loss: 1.0323 - accuracy: 0.5452 - val_loss: 0.9566 - val_accuracy: 0.5837\n",
      "Epoch 25/2000\n",
      "245/245 [==============================] - 0s 654us/step - loss: 1.0304 - accuracy: 0.5554 - val_loss: 0.9497 - val_accuracy: 0.5832\n",
      "Epoch 26/2000\n",
      "245/245 [==============================] - 0s 684us/step - loss: 1.0262 - accuracy: 0.5579 - val_loss: 0.9471 - val_accuracy: 0.5903\n",
      "Epoch 27/2000\n",
      "245/245 [==============================] - 0s 690us/step - loss: 1.0253 - accuracy: 0.5515 - val_loss: 0.9474 - val_accuracy: 0.5872\n",
      "Epoch 28/2000\n",
      "245/245 [==============================] - 0s 689us/step - loss: 1.0168 - accuracy: 0.5540 - val_loss: 0.9505 - val_accuracy: 0.5684\n",
      "Epoch 29/2000\n",
      "245/245 [==============================] - 0s 651us/step - loss: 1.0204 - accuracy: 0.5584 - val_loss: 0.9427 - val_accuracy: 0.5862\n",
      "Epoch 30/2000\n",
      "245/245 [==============================] - 0s 709us/step - loss: 1.0174 - accuracy: 0.5511 - val_loss: 0.9368 - val_accuracy: 0.5811\n",
      "Epoch 31/2000\n",
      "245/245 [==============================] - 0s 696us/step - loss: 1.0027 - accuracy: 0.5605 - val_loss: 0.9362 - val_accuracy: 0.5883\n",
      "Epoch 32/2000\n",
      "245/245 [==============================] - 0s 698us/step - loss: 1.0130 - accuracy: 0.5579 - val_loss: 0.9354 - val_accuracy: 0.5811\n",
      "Epoch 33/2000\n",
      "245/245 [==============================] - 0s 680us/step - loss: 1.0143 - accuracy: 0.5529 - val_loss: 0.9333 - val_accuracy: 0.5837\n",
      "Epoch 34/2000\n",
      "245/245 [==============================] - 0s 703us/step - loss: 1.0053 - accuracy: 0.5553 - val_loss: 0.9358 - val_accuracy: 0.5719\n",
      "Epoch 35/2000\n",
      "245/245 [==============================] - 0s 688us/step - loss: 1.0005 - accuracy: 0.5584 - val_loss: 0.9277 - val_accuracy: 0.5806\n",
      "Epoch 36/2000\n",
      "245/245 [==============================] - 0s 671us/step - loss: 0.9960 - accuracy: 0.5593 - val_loss: 0.9253 - val_accuracy: 0.5832\n",
      "Epoch 37/2000\n",
      "245/245 [==============================] - 0s 683us/step - loss: 1.0029 - accuracy: 0.5566 - val_loss: 0.9241 - val_accuracy: 0.5816\n",
      "Epoch 38/2000\n",
      "245/245 [==============================] - 0s 676us/step - loss: 0.9890 - accuracy: 0.5575 - val_loss: 0.9245 - val_accuracy: 0.5796\n",
      "Epoch 39/2000\n",
      "245/245 [==============================] - 0s 670us/step - loss: 0.9954 - accuracy: 0.5655 - val_loss: 0.9213 - val_accuracy: 0.5806\n",
      "Epoch 40/2000\n",
      "245/245 [==============================] - 0s 665us/step - loss: 0.9949 - accuracy: 0.5630 - val_loss: 0.9229 - val_accuracy: 0.5821\n",
      "Epoch 41/2000\n",
      "245/245 [==============================] - 0s 678us/step - loss: 0.9912 - accuracy: 0.5655 - val_loss: 0.9170 - val_accuracy: 0.5821\n",
      "Epoch 42/2000\n",
      "245/245 [==============================] - 0s 693us/step - loss: 0.9932 - accuracy: 0.5635 - val_loss: 0.9187 - val_accuracy: 0.5878\n",
      "Epoch 43/2000\n",
      "245/245 [==============================] - 0s 669us/step - loss: 0.9796 - accuracy: 0.5711 - val_loss: 0.9176 - val_accuracy: 0.5888\n",
      "Epoch 44/2000\n",
      "245/245 [==============================] - 0s 672us/step - loss: 0.9871 - accuracy: 0.5699 - val_loss: 0.9163 - val_accuracy: 0.5801\n",
      "Epoch 45/2000\n",
      "245/245 [==============================] - 0s 648us/step - loss: 0.9830 - accuracy: 0.5651 - val_loss: 0.9157 - val_accuracy: 0.5862\n",
      "Epoch 46/2000\n",
      "245/245 [==============================] - 0s 667us/step - loss: 0.9789 - accuracy: 0.5702 - val_loss: 0.9131 - val_accuracy: 0.5852\n",
      "Epoch 47/2000\n",
      "245/245 [==============================] - 0s 681us/step - loss: 0.9759 - accuracy: 0.5648 - val_loss: 0.9128 - val_accuracy: 0.5816\n",
      "Epoch 48/2000\n",
      "245/245 [==============================] - 0s 672us/step - loss: 0.9739 - accuracy: 0.5669 - val_loss: 0.9100 - val_accuracy: 0.5903\n",
      "Epoch 49/2000\n",
      "245/245 [==============================] - 0s 666us/step - loss: 0.9754 - accuracy: 0.5690 - val_loss: 0.9089 - val_accuracy: 0.6015\n",
      "Epoch 50/2000\n",
      "245/245 [==============================] - 0s 667us/step - loss: 0.9720 - accuracy: 0.5705 - val_loss: 0.9083 - val_accuracy: 0.5857\n",
      "Epoch 51/2000\n",
      "245/245 [==============================] - 0s 668us/step - loss: 0.9735 - accuracy: 0.5724 - val_loss: 0.9065 - val_accuracy: 0.5908\n",
      "Epoch 52/2000\n",
      "245/245 [==============================] - 0s 658us/step - loss: 0.9663 - accuracy: 0.5722 - val_loss: 0.9056 - val_accuracy: 0.5883\n",
      "Epoch 53/2000\n",
      "245/245 [==============================] - 0s 692us/step - loss: 0.9735 - accuracy: 0.5709 - val_loss: 0.9087 - val_accuracy: 0.5816\n",
      "Epoch 54/2000\n",
      "245/245 [==============================] - 0s 685us/step - loss: 0.9658 - accuracy: 0.5770 - val_loss: 0.9044 - val_accuracy: 0.5852\n",
      "Epoch 55/2000\n",
      "245/245 [==============================] - 0s 661us/step - loss: 0.9659 - accuracy: 0.5727 - val_loss: 0.9027 - val_accuracy: 0.5878\n",
      "Epoch 56/2000\n",
      "245/245 [==============================] - 0s 688us/step - loss: 0.9655 - accuracy: 0.5683 - val_loss: 0.9045 - val_accuracy: 0.5862\n",
      "Epoch 57/2000\n",
      "245/245 [==============================] - 0s 669us/step - loss: 0.9650 - accuracy: 0.5742 - val_loss: 0.8985 - val_accuracy: 0.5913\n",
      "Epoch 58/2000\n",
      "245/245 [==============================] - 0s 688us/step - loss: 0.9589 - accuracy: 0.5766 - val_loss: 0.8964 - val_accuracy: 0.5959\n",
      "Epoch 59/2000\n",
      "245/245 [==============================] - 0s 686us/step - loss: 0.9639 - accuracy: 0.5741 - val_loss: 0.8979 - val_accuracy: 0.5872\n",
      "Epoch 60/2000\n",
      "245/245 [==============================] - 0s 688us/step - loss: 0.9584 - accuracy: 0.5780 - val_loss: 0.8960 - val_accuracy: 0.5888\n",
      "Epoch 61/2000\n",
      "245/245 [==============================] - 0s 689us/step - loss: 0.9610 - accuracy: 0.5759 - val_loss: 0.8947 - val_accuracy: 0.5969\n",
      "Epoch 62/2000\n",
      "245/245 [==============================] - 0s 740us/step - loss: 0.9539 - accuracy: 0.5810 - val_loss: 0.8941 - val_accuracy: 0.5949\n",
      "Epoch 63/2000\n",
      "245/245 [==============================] - 0s 669us/step - loss: 0.9570 - accuracy: 0.5812 - val_loss: 0.8952 - val_accuracy: 0.5903\n",
      "Epoch 64/2000\n",
      "245/245 [==============================] - 0s 703us/step - loss: 0.9491 - accuracy: 0.5780 - val_loss: 0.8930 - val_accuracy: 0.5903\n",
      "Epoch 65/2000\n",
      "245/245 [==============================] - 0s 733us/step - loss: 0.9523 - accuracy: 0.5751 - val_loss: 0.8913 - val_accuracy: 0.5969\n",
      "Epoch 66/2000\n",
      "245/245 [==============================] - 0s 680us/step - loss: 0.9525 - accuracy: 0.5737 - val_loss: 0.8897 - val_accuracy: 0.5898\n",
      "Epoch 67/2000\n",
      "245/245 [==============================] - 0s 659us/step - loss: 0.9498 - accuracy: 0.5825 - val_loss: 0.8890 - val_accuracy: 0.6000\n",
      "Epoch 68/2000\n",
      "245/245 [==============================] - 0s 658us/step - loss: 0.9529 - accuracy: 0.5739 - val_loss: 0.8915 - val_accuracy: 0.5990\n",
      "Epoch 69/2000\n",
      "245/245 [==============================] - 0s 684us/step - loss: 0.9561 - accuracy: 0.5756 - val_loss: 0.8911 - val_accuracy: 0.5974\n",
      "Epoch 70/2000\n",
      "245/245 [==============================] - 0s 662us/step - loss: 0.9491 - accuracy: 0.5787 - val_loss: 0.8894 - val_accuracy: 0.5995\n",
      "Epoch 71/2000\n",
      "245/245 [==============================] - 0s 663us/step - loss: 0.9474 - accuracy: 0.5752 - val_loss: 0.8879 - val_accuracy: 0.5944\n",
      "Epoch 72/2000\n",
      "245/245 [==============================] - 0s 665us/step - loss: 0.9431 - accuracy: 0.5794 - val_loss: 0.8863 - val_accuracy: 0.5913\n",
      "Epoch 73/2000\n",
      "245/245 [==============================] - 0s 680us/step - loss: 0.9507 - accuracy: 0.5769 - val_loss: 0.8848 - val_accuracy: 0.5969\n",
      "Epoch 74/2000\n",
      "245/245 [==============================] - 0s 674us/step - loss: 0.9443 - accuracy: 0.5798 - val_loss: 0.8855 - val_accuracy: 0.6010\n",
      "Epoch 75/2000\n",
      "245/245 [==============================] - 0s 665us/step - loss: 0.9436 - accuracy: 0.5762 - val_loss: 0.8865 - val_accuracy: 0.5964\n",
      "Epoch 76/2000\n",
      "245/245 [==============================] - 0s 670us/step - loss: 0.9476 - accuracy: 0.5844 - val_loss: 0.8835 - val_accuracy: 0.6005\n",
      "Epoch 77/2000\n",
      "245/245 [==============================] - 0s 647us/step - loss: 0.9368 - accuracy: 0.5857 - val_loss: 0.8820 - val_accuracy: 0.6000\n",
      "Epoch 78/2000\n",
      "245/245 [==============================] - 0s 669us/step - loss: 0.9475 - accuracy: 0.5760 - val_loss: 0.8824 - val_accuracy: 0.5974\n",
      "Epoch 79/2000\n",
      "245/245 [==============================] - 0s 667us/step - loss: 0.9507 - accuracy: 0.5714 - val_loss: 0.8836 - val_accuracy: 0.6020\n",
      "Epoch 80/2000\n",
      "245/245 [==============================] - 0s 669us/step - loss: 0.9436 - accuracy: 0.5815 - val_loss: 0.8825 - val_accuracy: 0.5969\n",
      "Epoch 81/2000\n",
      "245/245 [==============================] - 0s 661us/step - loss: 0.9420 - accuracy: 0.5797 - val_loss: 0.8796 - val_accuracy: 0.6036\n",
      "Epoch 82/2000\n",
      "245/245 [==============================] - 0s 668us/step - loss: 0.9340 - accuracy: 0.5908 - val_loss: 0.8783 - val_accuracy: 0.6031\n",
      "Epoch 83/2000\n",
      "245/245 [==============================] - 0s 662us/step - loss: 0.9317 - accuracy: 0.5876 - val_loss: 0.8731 - val_accuracy: 0.6082\n",
      "Epoch 84/2000\n",
      "245/245 [==============================] - 0s 681us/step - loss: 0.9393 - accuracy: 0.5764 - val_loss: 0.8749 - val_accuracy: 0.6015\n",
      "Epoch 85/2000\n",
      "245/245 [==============================] - 0s 672us/step - loss: 0.9418 - accuracy: 0.5817 - val_loss: 0.8753 - val_accuracy: 0.6020\n",
      "Epoch 86/2000\n",
      "245/245 [==============================] - 0s 657us/step - loss: 0.9370 - accuracy: 0.5834 - val_loss: 0.8764 - val_accuracy: 0.6082\n",
      "Epoch 87/2000\n",
      "245/245 [==============================] - 0s 656us/step - loss: 0.9303 - accuracy: 0.5890 - val_loss: 0.8761 - val_accuracy: 0.6092\n",
      "Epoch 88/2000\n",
      "245/245 [==============================] - 0s 691us/step - loss: 0.9261 - accuracy: 0.5908 - val_loss: 0.8735 - val_accuracy: 0.6092\n",
      "Epoch 89/2000\n",
      "245/245 [==============================] - 0s 675us/step - loss: 0.9308 - accuracy: 0.5880 - val_loss: 0.8734 - val_accuracy: 0.6092\n",
      "Epoch 90/2000\n",
      "245/245 [==============================] - 0s 747us/step - loss: 0.9264 - accuracy: 0.5880 - val_loss: 0.8721 - val_accuracy: 0.6077\n",
      "Epoch 91/2000\n",
      "245/245 [==============================] - 0s 734us/step - loss: 0.9332 - accuracy: 0.5881 - val_loss: 0.8713 - val_accuracy: 0.6000\n",
      "Epoch 92/2000\n",
      "245/245 [==============================] - 0s 710us/step - loss: 0.9242 - accuracy: 0.5882 - val_loss: 0.8700 - val_accuracy: 0.6128\n",
      "Epoch 93/2000\n",
      "245/245 [==============================] - 0s 705us/step - loss: 0.9267 - accuracy: 0.5862 - val_loss: 0.8689 - val_accuracy: 0.6122\n",
      "Epoch 94/2000\n",
      "245/245 [==============================] - 0s 694us/step - loss: 0.9311 - accuracy: 0.5794 - val_loss: 0.8689 - val_accuracy: 0.6082\n",
      "Epoch 95/2000\n",
      "245/245 [==============================] - 0s 686us/step - loss: 0.9248 - accuracy: 0.5882 - val_loss: 0.8700 - val_accuracy: 0.6117\n",
      "Epoch 96/2000\n",
      "245/245 [==============================] - 0s 715us/step - loss: 0.9220 - accuracy: 0.5935 - val_loss: 0.8676 - val_accuracy: 0.6066\n",
      "Epoch 97/2000\n",
      "245/245 [==============================] - 0s 666us/step - loss: 0.9274 - accuracy: 0.5881 - val_loss: 0.8674 - val_accuracy: 0.6051\n",
      "Epoch 98/2000\n",
      "245/245 [==============================] - 0s 679us/step - loss: 0.9236 - accuracy: 0.5904 - val_loss: 0.8632 - val_accuracy: 0.6092\n",
      "Epoch 99/2000\n",
      "245/245 [==============================] - 0s 683us/step - loss: 0.9184 - accuracy: 0.5917 - val_loss: 0.8671 - val_accuracy: 0.6010\n",
      "Epoch 100/2000\n",
      "245/245 [==============================] - 0s 712us/step - loss: 0.9206 - accuracy: 0.5858 - val_loss: 0.8659 - val_accuracy: 0.6051\n",
      "Epoch 101/2000\n",
      "245/245 [==============================] - 0s 663us/step - loss: 0.9278 - accuracy: 0.5899 - val_loss: 0.8788 - val_accuracy: 0.6036\n",
      "Epoch 102/2000\n",
      "245/245 [==============================] - 0s 660us/step - loss: 0.9230 - accuracy: 0.5850 - val_loss: 0.8661 - val_accuracy: 0.6056\n",
      "Epoch 103/2000\n",
      "245/245 [==============================] - 0s 670us/step - loss: 0.9168 - accuracy: 0.5895 - val_loss: 0.8617 - val_accuracy: 0.6077\n",
      "Epoch 104/2000\n",
      "245/245 [==============================] - 0s 691us/step - loss: 0.9191 - accuracy: 0.5949 - val_loss: 0.8652 - val_accuracy: 0.6077\n",
      "Epoch 105/2000\n",
      "245/245 [==============================] - 0s 699us/step - loss: 0.9215 - accuracy: 0.5884 - val_loss: 0.8613 - val_accuracy: 0.6128\n",
      "Epoch 106/2000\n",
      "245/245 [==============================] - 0s 673us/step - loss: 0.9194 - accuracy: 0.5867 - val_loss: 0.8634 - val_accuracy: 0.6041\n",
      "Epoch 107/2000\n",
      "245/245 [==============================] - 0s 670us/step - loss: 0.9199 - accuracy: 0.5967 - val_loss: 0.8638 - val_accuracy: 0.6031\n",
      "Epoch 108/2000\n",
      "245/245 [==============================] - 0s 668us/step - loss: 0.9152 - accuracy: 0.5873 - val_loss: 0.8593 - val_accuracy: 0.6122\n",
      "Epoch 109/2000\n",
      "245/245 [==============================] - 0s 686us/step - loss: 0.9164 - accuracy: 0.5885 - val_loss: 0.8582 - val_accuracy: 0.6107\n",
      "Epoch 110/2000\n",
      "245/245 [==============================] - 0s 674us/step - loss: 0.9188 - accuracy: 0.5894 - val_loss: 0.8583 - val_accuracy: 0.6122\n",
      "Epoch 111/2000\n",
      "245/245 [==============================] - 0s 667us/step - loss: 0.9211 - accuracy: 0.5914 - val_loss: 0.8615 - val_accuracy: 0.6051\n",
      "Epoch 112/2000\n",
      "245/245 [==============================] - 0s 659us/step - loss: 0.9154 - accuracy: 0.5881 - val_loss: 0.8603 - val_accuracy: 0.6117\n",
      "Epoch 113/2000\n",
      "245/245 [==============================] - 0s 683us/step - loss: 0.9135 - accuracy: 0.5933 - val_loss: 0.8580 - val_accuracy: 0.6077\n",
      "Epoch 114/2000\n",
      "245/245 [==============================] - 0s 651us/step - loss: 0.9143 - accuracy: 0.5924 - val_loss: 0.8580 - val_accuracy: 0.6107\n",
      "Epoch 115/2000\n",
      "245/245 [==============================] - 0s 667us/step - loss: 0.9144 - accuracy: 0.5947 - val_loss: 0.8560 - val_accuracy: 0.6117\n",
      "Epoch 116/2000\n",
      "245/245 [==============================] - 0s 681us/step - loss: 0.9125 - accuracy: 0.5928 - val_loss: 0.8594 - val_accuracy: 0.6087\n",
      "Epoch 117/2000\n",
      "245/245 [==============================] - 0s 726us/step - loss: 0.9135 - accuracy: 0.5930 - val_loss: 0.8539 - val_accuracy: 0.6189\n",
      "Epoch 118/2000\n",
      "245/245 [==============================] - 0s 696us/step - loss: 0.9044 - accuracy: 0.5956 - val_loss: 0.8525 - val_accuracy: 0.6066\n",
      "Epoch 119/2000\n",
      "245/245 [==============================] - 0s 655us/step - loss: 0.9100 - accuracy: 0.5968 - val_loss: 0.8532 - val_accuracy: 0.6143\n",
      "Epoch 120/2000\n",
      "245/245 [==============================] - 0s 673us/step - loss: 0.9116 - accuracy: 0.5956 - val_loss: 0.8545 - val_accuracy: 0.6153\n",
      "Epoch 121/2000\n",
      "245/245 [==============================] - 0s 659us/step - loss: 0.9117 - accuracy: 0.5951 - val_loss: 0.8521 - val_accuracy: 0.6179\n",
      "Epoch 122/2000\n",
      "245/245 [==============================] - 0s 653us/step - loss: 0.9109 - accuracy: 0.5937 - val_loss: 0.8523 - val_accuracy: 0.6184\n",
      "Epoch 123/2000\n",
      "245/245 [==============================] - 0s 655us/step - loss: 0.9036 - accuracy: 0.5936 - val_loss: 0.8484 - val_accuracy: 0.6230\n",
      "Epoch 124/2000\n",
      "245/245 [==============================] - 0s 678us/step - loss: 0.9048 - accuracy: 0.5972 - val_loss: 0.8464 - val_accuracy: 0.6255\n",
      "Epoch 125/2000\n",
      "245/245 [==============================] - 0s 657us/step - loss: 0.9144 - accuracy: 0.5937 - val_loss: 0.8513 - val_accuracy: 0.6128\n",
      "Epoch 126/2000\n",
      "245/245 [==============================] - 0s 672us/step - loss: 0.9061 - accuracy: 0.5930 - val_loss: 0.8480 - val_accuracy: 0.6179\n",
      "Epoch 127/2000\n",
      "245/245 [==============================] - 0s 677us/step - loss: 0.9047 - accuracy: 0.6006 - val_loss: 0.8485 - val_accuracy: 0.6224\n",
      "Epoch 128/2000\n",
      "245/245 [==============================] - 0s 666us/step - loss: 0.9073 - accuracy: 0.5949 - val_loss: 0.8520 - val_accuracy: 0.6184\n",
      "Epoch 129/2000\n",
      "245/245 [==============================] - 0s 667us/step - loss: 0.9118 - accuracy: 0.5926 - val_loss: 0.8453 - val_accuracy: 0.6138\n",
      "Epoch 130/2000\n",
      "245/245 [==============================] - 0s 676us/step - loss: 0.9074 - accuracy: 0.5969 - val_loss: 0.8500 - val_accuracy: 0.6117\n",
      "Epoch 131/2000\n",
      "245/245 [==============================] - 0s 671us/step - loss: 0.9015 - accuracy: 0.6009 - val_loss: 0.8516 - val_accuracy: 0.6163\n",
      "Epoch 132/2000\n",
      "245/245 [==============================] - 0s 725us/step - loss: 0.9072 - accuracy: 0.5922 - val_loss: 0.8462 - val_accuracy: 0.6143\n",
      "Epoch 133/2000\n",
      "245/245 [==============================] - 0s 708us/step - loss: 0.9034 - accuracy: 0.5928 - val_loss: 0.8525 - val_accuracy: 0.6117\n",
      "Epoch 134/2000\n",
      "245/245 [==============================] - 0s 669us/step - loss: 0.9012 - accuracy: 0.5987 - val_loss: 0.8426 - val_accuracy: 0.6179\n",
      "Epoch 135/2000\n",
      "245/245 [==============================] - 0s 660us/step - loss: 0.8975 - accuracy: 0.5991 - val_loss: 0.8453 - val_accuracy: 0.6194\n",
      "Epoch 136/2000\n",
      "245/245 [==============================] - 0s 653us/step - loss: 0.9096 - accuracy: 0.5978 - val_loss: 0.8428 - val_accuracy: 0.6230\n",
      "Epoch 137/2000\n",
      "245/245 [==============================] - 0s 650us/step - loss: 0.8960 - accuracy: 0.6019 - val_loss: 0.8433 - val_accuracy: 0.6158\n",
      "Epoch 138/2000\n",
      "245/245 [==============================] - 0s 675us/step - loss: 0.8932 - accuracy: 0.6020 - val_loss: 0.8436 - val_accuracy: 0.6224\n",
      "Epoch 139/2000\n",
      "245/245 [==============================] - 0s 647us/step - loss: 0.9009 - accuracy: 0.6016 - val_loss: 0.8416 - val_accuracy: 0.6153\n",
      "Epoch 140/2000\n",
      "245/245 [==============================] - 0s 654us/step - loss: 0.8971 - accuracy: 0.5944 - val_loss: 0.8401 - val_accuracy: 0.6230\n",
      "Epoch 141/2000\n",
      "245/245 [==============================] - 0s 680us/step - loss: 0.9051 - accuracy: 0.5928 - val_loss: 0.8382 - val_accuracy: 0.6214\n",
      "Epoch 142/2000\n",
      "245/245 [==============================] - 0s 673us/step - loss: 0.8983 - accuracy: 0.5889 - val_loss: 0.8417 - val_accuracy: 0.6260\n",
      "Epoch 143/2000\n",
      "245/245 [==============================] - 0s 675us/step - loss: 0.8969 - accuracy: 0.5984 - val_loss: 0.8413 - val_accuracy: 0.6235\n",
      "Epoch 144/2000\n",
      "245/245 [==============================] - 0s 698us/step - loss: 0.8977 - accuracy: 0.6009 - val_loss: 0.8429 - val_accuracy: 0.6143\n",
      "Epoch 145/2000\n",
      "245/245 [==============================] - 0s 700us/step - loss: 0.8968 - accuracy: 0.5963 - val_loss: 0.8399 - val_accuracy: 0.6204\n",
      "Epoch 146/2000\n",
      "245/245 [==============================] - 0s 682us/step - loss: 0.8925 - accuracy: 0.6023 - val_loss: 0.8386 - val_accuracy: 0.6260\n",
      "Epoch 147/2000\n",
      "245/245 [==============================] - 0s 666us/step - loss: 0.9033 - accuracy: 0.5987 - val_loss: 0.8376 - val_accuracy: 0.6189\n",
      "Epoch 148/2000\n",
      "245/245 [==============================] - 0s 675us/step - loss: 0.8955 - accuracy: 0.5978 - val_loss: 0.8350 - val_accuracy: 0.6173\n",
      "Epoch 149/2000\n",
      "245/245 [==============================] - 0s 659us/step - loss: 0.8959 - accuracy: 0.6032 - val_loss: 0.8348 - val_accuracy: 0.6281\n",
      "Epoch 150/2000\n",
      "245/245 [==============================] - 0s 666us/step - loss: 0.8973 - accuracy: 0.5991 - val_loss: 0.8352 - val_accuracy: 0.6276\n",
      "Epoch 151/2000\n",
      "245/245 [==============================] - 0s 662us/step - loss: 0.8941 - accuracy: 0.6018 - val_loss: 0.8368 - val_accuracy: 0.6194\n",
      "Epoch 152/2000\n",
      "245/245 [==============================] - 0s 671us/step - loss: 0.9001 - accuracy: 0.5947 - val_loss: 0.8326 - val_accuracy: 0.6240\n",
      "Epoch 153/2000\n",
      "245/245 [==============================] - 0s 667us/step - loss: 0.8952 - accuracy: 0.6043 - val_loss: 0.8303 - val_accuracy: 0.6306\n",
      "Epoch 154/2000\n",
      "245/245 [==============================] - 0s 671us/step - loss: 0.8866 - accuracy: 0.6025 - val_loss: 0.8293 - val_accuracy: 0.6265\n",
      "Epoch 155/2000\n",
      "245/245 [==============================] - 0s 669us/step - loss: 0.8859 - accuracy: 0.6023 - val_loss: 0.8284 - val_accuracy: 0.6173\n",
      "Epoch 156/2000\n",
      "245/245 [==============================] - 0s 695us/step - loss: 0.8874 - accuracy: 0.6075 - val_loss: 0.8284 - val_accuracy: 0.6332\n",
      "Epoch 157/2000\n",
      "245/245 [==============================] - 0s 666us/step - loss: 0.8901 - accuracy: 0.5978 - val_loss: 0.8298 - val_accuracy: 0.6270\n",
      "Epoch 158/2000\n",
      "245/245 [==============================] - 0s 660us/step - loss: 0.8893 - accuracy: 0.6067 - val_loss: 0.8291 - val_accuracy: 0.6230\n",
      "Epoch 159/2000\n",
      "245/245 [==============================] - 0s 668us/step - loss: 0.8898 - accuracy: 0.6015 - val_loss: 0.8261 - val_accuracy: 0.6281\n",
      "Epoch 160/2000\n",
      "245/245 [==============================] - 0s 652us/step - loss: 0.8918 - accuracy: 0.6033 - val_loss: 0.8301 - val_accuracy: 0.6270\n",
      "Epoch 161/2000\n",
      "245/245 [==============================] - 0s 653us/step - loss: 0.8877 - accuracy: 0.6019 - val_loss: 0.8282 - val_accuracy: 0.6260\n",
      "Epoch 162/2000\n",
      "245/245 [==============================] - 0s 645us/step - loss: 0.8865 - accuracy: 0.6011 - val_loss: 0.8225 - val_accuracy: 0.6209\n",
      "Epoch 163/2000\n",
      "245/245 [==============================] - 0s 656us/step - loss: 0.8882 - accuracy: 0.6029 - val_loss: 0.8255 - val_accuracy: 0.6270\n",
      "Epoch 164/2000\n",
      "245/245 [==============================] - 0s 673us/step - loss: 0.8900 - accuracy: 0.6005 - val_loss: 0.8251 - val_accuracy: 0.6214\n",
      "Epoch 165/2000\n",
      "245/245 [==============================] - 0s 686us/step - loss: 0.8851 - accuracy: 0.6030 - val_loss: 0.8246 - val_accuracy: 0.6270\n",
      "Epoch 166/2000\n",
      "245/245 [==============================] - 0s 646us/step - loss: 0.8865 - accuracy: 0.6002 - val_loss: 0.8202 - val_accuracy: 0.6255\n",
      "Epoch 167/2000\n",
      "245/245 [==============================] - 0s 662us/step - loss: 0.8855 - accuracy: 0.6035 - val_loss: 0.8224 - val_accuracy: 0.6281\n",
      "Epoch 168/2000\n",
      "245/245 [==============================] - 0s 662us/step - loss: 0.8882 - accuracy: 0.6079 - val_loss: 0.8233 - val_accuracy: 0.6189\n",
      "Epoch 169/2000\n",
      "245/245 [==============================] - 0s 655us/step - loss: 0.8869 - accuracy: 0.6038 - val_loss: 0.8229 - val_accuracy: 0.6194\n",
      "Epoch 170/2000\n",
      "245/245 [==============================] - 0s 659us/step - loss: 0.8780 - accuracy: 0.6055 - val_loss: 0.8191 - val_accuracy: 0.6235\n",
      "Epoch 171/2000\n",
      "245/245 [==============================] - 0s 681us/step - loss: 0.8864 - accuracy: 0.6035 - val_loss: 0.8198 - val_accuracy: 0.6408\n",
      "Epoch 172/2000\n",
      "245/245 [==============================] - 0s 658us/step - loss: 0.8763 - accuracy: 0.6078 - val_loss: 0.8189 - val_accuracy: 0.6291\n",
      "Epoch 173/2000\n",
      "245/245 [==============================] - 0s 665us/step - loss: 0.8782 - accuracy: 0.6065 - val_loss: 0.8208 - val_accuracy: 0.6316\n",
      "Epoch 174/2000\n",
      "245/245 [==============================] - 0s 665us/step - loss: 0.8770 - accuracy: 0.6101 - val_loss: 0.8194 - val_accuracy: 0.6357\n",
      "Epoch 175/2000\n",
      "245/245 [==============================] - 0s 658us/step - loss: 0.8762 - accuracy: 0.6065 - val_loss: 0.8150 - val_accuracy: 0.6235\n",
      "Epoch 176/2000\n",
      "245/245 [==============================] - 0s 659us/step - loss: 0.8783 - accuracy: 0.6069 - val_loss: 0.8148 - val_accuracy: 0.6245\n",
      "Epoch 177/2000\n",
      "245/245 [==============================] - 0s 666us/step - loss: 0.8789 - accuracy: 0.6121 - val_loss: 0.8178 - val_accuracy: 0.6444\n",
      "Epoch 178/2000\n",
      "245/245 [==============================] - 0s 656us/step - loss: 0.8711 - accuracy: 0.6112 - val_loss: 0.8165 - val_accuracy: 0.6321\n",
      "Epoch 179/2000\n",
      "245/245 [==============================] - 0s 666us/step - loss: 0.8760 - accuracy: 0.6085 - val_loss: 0.8116 - val_accuracy: 0.6393\n",
      "Epoch 180/2000\n",
      "245/245 [==============================] - 0s 675us/step - loss: 0.8668 - accuracy: 0.6161 - val_loss: 0.8099 - val_accuracy: 0.6398\n",
      "Epoch 181/2000\n",
      "245/245 [==============================] - 0s 651us/step - loss: 0.8730 - accuracy: 0.6121 - val_loss: 0.8108 - val_accuracy: 0.6281\n",
      "Epoch 182/2000\n",
      "245/245 [==============================] - 0s 657us/step - loss: 0.8737 - accuracy: 0.6113 - val_loss: 0.8118 - val_accuracy: 0.6434\n",
      "Epoch 183/2000\n",
      "245/245 [==============================] - 0s 737us/step - loss: 0.8728 - accuracy: 0.6087 - val_loss: 0.8095 - val_accuracy: 0.6383\n",
      "Epoch 184/2000\n",
      "245/245 [==============================] - 0s 657us/step - loss: 0.8735 - accuracy: 0.6136 - val_loss: 0.8098 - val_accuracy: 0.6418\n",
      "Epoch 185/2000\n",
      "245/245 [==============================] - 0s 681us/step - loss: 0.8753 - accuracy: 0.6190 - val_loss: 0.8114 - val_accuracy: 0.6398\n",
      "Epoch 186/2000\n",
      "245/245 [==============================] - 0s 670us/step - loss: 0.8719 - accuracy: 0.6163 - val_loss: 0.8074 - val_accuracy: 0.6439\n",
      "Epoch 187/2000\n",
      "245/245 [==============================] - 0s 667us/step - loss: 0.8718 - accuracy: 0.6131 - val_loss: 0.8062 - val_accuracy: 0.6413\n",
      "Epoch 188/2000\n",
      "245/245 [==============================] - 0s 663us/step - loss: 0.8792 - accuracy: 0.6104 - val_loss: 0.8067 - val_accuracy: 0.6423\n",
      "Epoch 189/2000\n",
      "245/245 [==============================] - 0s 652us/step - loss: 0.8719 - accuracy: 0.6143 - val_loss: 0.8090 - val_accuracy: 0.6429\n",
      "Epoch 190/2000\n",
      "245/245 [==============================] - 0s 659us/step - loss: 0.8695 - accuracy: 0.6175 - val_loss: 0.8080 - val_accuracy: 0.6429\n",
      "Epoch 191/2000\n",
      "245/245 [==============================] - 0s 659us/step - loss: 0.8712 - accuracy: 0.6152 - val_loss: 0.8053 - val_accuracy: 0.6429\n",
      "Epoch 192/2000\n",
      "245/245 [==============================] - 0s 666us/step - loss: 0.8731 - accuracy: 0.6152 - val_loss: 0.8091 - val_accuracy: 0.6311\n",
      "Epoch 193/2000\n",
      "245/245 [==============================] - 0s 653us/step - loss: 0.8707 - accuracy: 0.6138 - val_loss: 0.8038 - val_accuracy: 0.6449\n",
      "Epoch 194/2000\n",
      "245/245 [==============================] - 0s 670us/step - loss: 0.8720 - accuracy: 0.6148 - val_loss: 0.8045 - val_accuracy: 0.6413\n",
      "Epoch 195/2000\n",
      "245/245 [==============================] - 0s 654us/step - loss: 0.8758 - accuracy: 0.6152 - val_loss: 0.8079 - val_accuracy: 0.6393\n",
      "Epoch 196/2000\n",
      "245/245 [==============================] - 0s 663us/step - loss: 0.8705 - accuracy: 0.6146 - val_loss: 0.8039 - val_accuracy: 0.6418\n",
      "Epoch 197/2000\n",
      "245/245 [==============================] - 0s 653us/step - loss: 0.8670 - accuracy: 0.6195 - val_loss: 0.8034 - val_accuracy: 0.6459\n",
      "Epoch 198/2000\n",
      "245/245 [==============================] - 0s 662us/step - loss: 0.8671 - accuracy: 0.6093 - val_loss: 0.8045 - val_accuracy: 0.6474\n",
      "Epoch 199/2000\n",
      "245/245 [==============================] - 0s 665us/step - loss: 0.8689 - accuracy: 0.6124 - val_loss: 0.8017 - val_accuracy: 0.6444\n",
      "Epoch 200/2000\n",
      "245/245 [==============================] - 0s 662us/step - loss: 0.8679 - accuracy: 0.6182 - val_loss: 0.8018 - val_accuracy: 0.6459\n",
      "Epoch 201/2000\n",
      "245/245 [==============================] - 0s 688us/step - loss: 0.8661 - accuracy: 0.6195 - val_loss: 0.8057 - val_accuracy: 0.6449\n",
      "Epoch 202/2000\n",
      "245/245 [==============================] - 0s 673us/step - loss: 0.8690 - accuracy: 0.6118 - val_loss: 0.8030 - val_accuracy: 0.6480\n",
      "Epoch 203/2000\n",
      "245/245 [==============================] - 0s 658us/step - loss: 0.8675 - accuracy: 0.6158 - val_loss: 0.8003 - val_accuracy: 0.6367\n",
      "Epoch 204/2000\n",
      "245/245 [==============================] - 0s 657us/step - loss: 0.8686 - accuracy: 0.6158 - val_loss: 0.8014 - val_accuracy: 0.6423\n",
      "Epoch 205/2000\n",
      "245/245 [==============================] - 0s 659us/step - loss: 0.8629 - accuracy: 0.6098 - val_loss: 0.8003 - val_accuracy: 0.6439\n",
      "Epoch 206/2000\n",
      "245/245 [==============================] - 0s 672us/step - loss: 0.8577 - accuracy: 0.6219 - val_loss: 0.7977 - val_accuracy: 0.6418\n",
      "Epoch 207/2000\n",
      "245/245 [==============================] - 0s 681us/step - loss: 0.8694 - accuracy: 0.6194 - val_loss: 0.7979 - val_accuracy: 0.6444\n",
      "Epoch 208/2000\n",
      "245/245 [==============================] - 0s 691us/step - loss: 0.8613 - accuracy: 0.6111 - val_loss: 0.7981 - val_accuracy: 0.6439\n",
      "Epoch 209/2000\n",
      "245/245 [==============================] - 0s 674us/step - loss: 0.8635 - accuracy: 0.6189 - val_loss: 0.7984 - val_accuracy: 0.6408\n",
      "Epoch 210/2000\n",
      "245/245 [==============================] - 0s 682us/step - loss: 0.8608 - accuracy: 0.6173 - val_loss: 0.7981 - val_accuracy: 0.6480\n",
      "Epoch 211/2000\n",
      "245/245 [==============================] - 0s 667us/step - loss: 0.8584 - accuracy: 0.6219 - val_loss: 0.7970 - val_accuracy: 0.6474\n",
      "Epoch 212/2000\n",
      "245/245 [==============================] - 0s 679us/step - loss: 0.8614 - accuracy: 0.6195 - val_loss: 0.7979 - val_accuracy: 0.6429\n",
      "Epoch 213/2000\n",
      "245/245 [==============================] - 0s 660us/step - loss: 0.8677 - accuracy: 0.6196 - val_loss: 0.7943 - val_accuracy: 0.6418\n",
      "Epoch 214/2000\n",
      "245/245 [==============================] - 0s 659us/step - loss: 0.8537 - accuracy: 0.6210 - val_loss: 0.7995 - val_accuracy: 0.6510\n",
      "Epoch 215/2000\n",
      "245/245 [==============================] - 0s 671us/step - loss: 0.8544 - accuracy: 0.6232 - val_loss: 0.7983 - val_accuracy: 0.6474\n",
      "Epoch 216/2000\n",
      "245/245 [==============================] - 0s 663us/step - loss: 0.8579 - accuracy: 0.6192 - val_loss: 0.7969 - val_accuracy: 0.6495\n",
      "Epoch 217/2000\n",
      "245/245 [==============================] - 0s 710us/step - loss: 0.8554 - accuracy: 0.6158 - val_loss: 0.7918 - val_accuracy: 0.6423\n",
      "Epoch 218/2000\n",
      "245/245 [==============================] - 0s 660us/step - loss: 0.8579 - accuracy: 0.6242 - val_loss: 0.7901 - val_accuracy: 0.6423\n",
      "Epoch 219/2000\n",
      "245/245 [==============================] - 0s 657us/step - loss: 0.8564 - accuracy: 0.6182 - val_loss: 0.7902 - val_accuracy: 0.6444\n",
      "Epoch 220/2000\n",
      "245/245 [==============================] - 0s 664us/step - loss: 0.8510 - accuracy: 0.6242 - val_loss: 0.7988 - val_accuracy: 0.6510\n",
      "Epoch 221/2000\n",
      "245/245 [==============================] - 0s 671us/step - loss: 0.8552 - accuracy: 0.6204 - val_loss: 0.7933 - val_accuracy: 0.6474\n",
      "Epoch 222/2000\n",
      "245/245 [==============================] - 0s 660us/step - loss: 0.8570 - accuracy: 0.6218 - val_loss: 0.7871 - val_accuracy: 0.6337\n",
      "Epoch 223/2000\n",
      "245/245 [==============================] - 0s 639us/step - loss: 0.8543 - accuracy: 0.6192 - val_loss: 0.7935 - val_accuracy: 0.6449\n",
      "Epoch 224/2000\n",
      "245/245 [==============================] - 0s 656us/step - loss: 0.8566 - accuracy: 0.6257 - val_loss: 0.7951 - val_accuracy: 0.6347\n",
      "Epoch 225/2000\n",
      "245/245 [==============================] - 0s 669us/step - loss: 0.8579 - accuracy: 0.6139 - val_loss: 0.7885 - val_accuracy: 0.6408\n",
      "Epoch 226/2000\n",
      "245/245 [==============================] - 0s 683us/step - loss: 0.8543 - accuracy: 0.6233 - val_loss: 0.7893 - val_accuracy: 0.6327\n",
      "Epoch 227/2000\n",
      "245/245 [==============================] - 0s 705us/step - loss: 0.8553 - accuracy: 0.6236 - val_loss: 0.7910 - val_accuracy: 0.6485\n",
      "Epoch 228/2000\n",
      "245/245 [==============================] - 0s 677us/step - loss: 0.8492 - accuracy: 0.6214 - val_loss: 0.7827 - val_accuracy: 0.6459\n",
      "Epoch 229/2000\n",
      "245/245 [==============================] - 0s 658us/step - loss: 0.8528 - accuracy: 0.6190 - val_loss: 0.7927 - val_accuracy: 0.6541\n",
      "Epoch 230/2000\n",
      "245/245 [==============================] - 0s 657us/step - loss: 0.8499 - accuracy: 0.6243 - val_loss: 0.7886 - val_accuracy: 0.6469\n",
      "Epoch 231/2000\n",
      "245/245 [==============================] - 0s 657us/step - loss: 0.8554 - accuracy: 0.6265 - val_loss: 0.7876 - val_accuracy: 0.6372\n",
      "Epoch 232/2000\n",
      "245/245 [==============================] - 0s 661us/step - loss: 0.8510 - accuracy: 0.6219 - val_loss: 0.7878 - val_accuracy: 0.6418\n",
      "Epoch 233/2000\n",
      "245/245 [==============================] - 0s 701us/step - loss: 0.8483 - accuracy: 0.6183 - val_loss: 0.7886 - val_accuracy: 0.6408\n",
      "Epoch 234/2000\n",
      "245/245 [==============================] - 0s 650us/step - loss: 0.8582 - accuracy: 0.6191 - val_loss: 0.7896 - val_accuracy: 0.6378\n",
      "Epoch 235/2000\n",
      "245/245 [==============================] - 0s 667us/step - loss: 0.8504 - accuracy: 0.6228 - val_loss: 0.7802 - val_accuracy: 0.6423\n",
      "Epoch 236/2000\n",
      "245/245 [==============================] - 0s 673us/step - loss: 0.8539 - accuracy: 0.6219 - val_loss: 0.7838 - val_accuracy: 0.6418\n",
      "Epoch 237/2000\n",
      "245/245 [==============================] - 0s 667us/step - loss: 0.8521 - accuracy: 0.6250 - val_loss: 0.7849 - val_accuracy: 0.6459\n",
      "Epoch 238/2000\n",
      "245/245 [==============================] - 0s 660us/step - loss: 0.8491 - accuracy: 0.6246 - val_loss: 0.7844 - val_accuracy: 0.6444\n",
      "Epoch 239/2000\n",
      "245/245 [==============================] - 0s 666us/step - loss: 0.8527 - accuracy: 0.6226 - val_loss: 0.7844 - val_accuracy: 0.6526\n",
      "Epoch 240/2000\n",
      "245/245 [==============================] - 0s 660us/step - loss: 0.8494 - accuracy: 0.6265 - val_loss: 0.7793 - val_accuracy: 0.6464\n",
      "Epoch 241/2000\n",
      "245/245 [==============================] - 0s 671us/step - loss: 0.8552 - accuracy: 0.6201 - val_loss: 0.7831 - val_accuracy: 0.6403\n",
      "Epoch 242/2000\n",
      "245/245 [==============================] - 0s 696us/step - loss: 0.8444 - accuracy: 0.6334 - val_loss: 0.7851 - val_accuracy: 0.6362\n",
      "Epoch 243/2000\n",
      "245/245 [==============================] - 0s 652us/step - loss: 0.8477 - accuracy: 0.6219 - val_loss: 0.7873 - val_accuracy: 0.6418\n",
      "Epoch 244/2000\n",
      "245/245 [==============================] - 0s 661us/step - loss: 0.8507 - accuracy: 0.6273 - val_loss: 0.7870 - val_accuracy: 0.6357\n",
      "Epoch 245/2000\n",
      "245/245 [==============================] - 0s 664us/step - loss: 0.8550 - accuracy: 0.6168 - val_loss: 0.7818 - val_accuracy: 0.6429\n",
      "Epoch 246/2000\n",
      "245/245 [==============================] - 0s 663us/step - loss: 0.8488 - accuracy: 0.6268 - val_loss: 0.7870 - val_accuracy: 0.6418\n",
      "Epoch 247/2000\n",
      "245/245 [==============================] - 0s 674us/step - loss: 0.8443 - accuracy: 0.6275 - val_loss: 0.7784 - val_accuracy: 0.6464\n",
      "Epoch 248/2000\n",
      "245/245 [==============================] - 0s 664us/step - loss: 0.8430 - accuracy: 0.6254 - val_loss: 0.7805 - val_accuracy: 0.6526\n",
      "Epoch 249/2000\n",
      "245/245 [==============================] - 0s 676us/step - loss: 0.8445 - accuracy: 0.6245 - val_loss: 0.7785 - val_accuracy: 0.6459\n",
      "Epoch 250/2000\n",
      "245/245 [==============================] - 0s 649us/step - loss: 0.8448 - accuracy: 0.6246 - val_loss: 0.7776 - val_accuracy: 0.6316\n",
      "Epoch 251/2000\n",
      "245/245 [==============================] - 0s 668us/step - loss: 0.8486 - accuracy: 0.6291 - val_loss: 0.7825 - val_accuracy: 0.6444\n",
      "Epoch 252/2000\n",
      "245/245 [==============================] - 0s 662us/step - loss: 0.8466 - accuracy: 0.6256 - val_loss: 0.7785 - val_accuracy: 0.6500\n",
      "Epoch 253/2000\n",
      "245/245 [==============================] - 0s 653us/step - loss: 0.8437 - accuracy: 0.6263 - val_loss: 0.7777 - val_accuracy: 0.6434\n",
      "Epoch 254/2000\n",
      "245/245 [==============================] - 0s 664us/step - loss: 0.8449 - accuracy: 0.6321 - val_loss: 0.7727 - val_accuracy: 0.6439\n",
      "Epoch 255/2000\n",
      "245/245 [==============================] - 0s 675us/step - loss: 0.8435 - accuracy: 0.6183 - val_loss: 0.7730 - val_accuracy: 0.6464\n",
      "Epoch 256/2000\n",
      "245/245 [==============================] - 0s 661us/step - loss: 0.8417 - accuracy: 0.6245 - val_loss: 0.7766 - val_accuracy: 0.6413\n",
      "Epoch 257/2000\n",
      "245/245 [==============================] - 0s 657us/step - loss: 0.8389 - accuracy: 0.6280 - val_loss: 0.7749 - val_accuracy: 0.6515\n",
      "Epoch 258/2000\n",
      "245/245 [==============================] - 0s 664us/step - loss: 0.8449 - accuracy: 0.6243 - val_loss: 0.7845 - val_accuracy: 0.6490\n",
      "Epoch 259/2000\n",
      "245/245 [==============================] - 0s 651us/step - loss: 0.8352 - accuracy: 0.6247 - val_loss: 0.7758 - val_accuracy: 0.6454\n",
      "Epoch 260/2000\n",
      "245/245 [==============================] - 0s 653us/step - loss: 0.8358 - accuracy: 0.6287 - val_loss: 0.7738 - val_accuracy: 0.6469\n",
      "Epoch 261/2000\n",
      "245/245 [==============================] - 0s 691us/step - loss: 0.8470 - accuracy: 0.6269 - val_loss: 0.7764 - val_accuracy: 0.6520\n",
      "Epoch 262/2000\n",
      "245/245 [==============================] - 0s 662us/step - loss: 0.8432 - accuracy: 0.6268 - val_loss: 0.7734 - val_accuracy: 0.6515\n",
      "Epoch 263/2000\n",
      "245/245 [==============================] - 0s 661us/step - loss: 0.8402 - accuracy: 0.6283 - val_loss: 0.7748 - val_accuracy: 0.6347\n",
      "Epoch 264/2000\n",
      "245/245 [==============================] - 0s 672us/step - loss: 0.8477 - accuracy: 0.6254 - val_loss: 0.7757 - val_accuracy: 0.6469\n",
      "Epoch 265/2000\n",
      "245/245 [==============================] - 0s 652us/step - loss: 0.8357 - accuracy: 0.6292 - val_loss: 0.7708 - val_accuracy: 0.6459\n",
      "Epoch 266/2000\n",
      "245/245 [==============================] - 0s 678us/step - loss: 0.8350 - accuracy: 0.6300 - val_loss: 0.7702 - val_accuracy: 0.6480\n",
      "Epoch 267/2000\n",
      "245/245 [==============================] - 0s 661us/step - loss: 0.8315 - accuracy: 0.6311 - val_loss: 0.7706 - val_accuracy: 0.6474\n",
      "Epoch 268/2000\n",
      "245/245 [==============================] - 0s 655us/step - loss: 0.8422 - accuracy: 0.6310 - val_loss: 0.7708 - val_accuracy: 0.6403\n",
      "Epoch 269/2000\n",
      "245/245 [==============================] - 0s 657us/step - loss: 0.8406 - accuracy: 0.6319 - val_loss: 0.7702 - val_accuracy: 0.6510\n",
      "Epoch 270/2000\n",
      "245/245 [==============================] - 0s 676us/step - loss: 0.8375 - accuracy: 0.6254 - val_loss: 0.7728 - val_accuracy: 0.6485\n",
      "Epoch 271/2000\n",
      "245/245 [==============================] - 0s 674us/step - loss: 0.8353 - accuracy: 0.6380 - val_loss: 0.7706 - val_accuracy: 0.6439\n",
      "Epoch 272/2000\n",
      "245/245 [==============================] - 0s 664us/step - loss: 0.8333 - accuracy: 0.6338 - val_loss: 0.7670 - val_accuracy: 0.6500\n",
      "Epoch 273/2000\n",
      "245/245 [==============================] - 0s 667us/step - loss: 0.8398 - accuracy: 0.6301 - val_loss: 0.7706 - val_accuracy: 0.6546\n",
      "Epoch 274/2000\n",
      "245/245 [==============================] - 0s 684us/step - loss: 0.8393 - accuracy: 0.6298 - val_loss: 0.7729 - val_accuracy: 0.6551\n",
      "Epoch 275/2000\n",
      "245/245 [==============================] - 0s 650us/step - loss: 0.8300 - accuracy: 0.6372 - val_loss: 0.7705 - val_accuracy: 0.6413\n",
      "Epoch 276/2000\n",
      "245/245 [==============================] - 0s 671us/step - loss: 0.8397 - accuracy: 0.6297 - val_loss: 0.7703 - val_accuracy: 0.6526\n",
      "Epoch 277/2000\n",
      "245/245 [==============================] - 0s 642us/step - loss: 0.8368 - accuracy: 0.6344 - val_loss: 0.7664 - val_accuracy: 0.6526\n",
      "Epoch 278/2000\n",
      "245/245 [==============================] - 0s 681us/step - loss: 0.8330 - accuracy: 0.6291 - val_loss: 0.7689 - val_accuracy: 0.6444\n",
      "Epoch 279/2000\n",
      "245/245 [==============================] - 0s 675us/step - loss: 0.8289 - accuracy: 0.6398 - val_loss: 0.7639 - val_accuracy: 0.6541\n",
      "Epoch 280/2000\n",
      "245/245 [==============================] - 0s 658us/step - loss: 0.8325 - accuracy: 0.6347 - val_loss: 0.7699 - val_accuracy: 0.6474\n",
      "Epoch 281/2000\n",
      "245/245 [==============================] - 0s 681us/step - loss: 0.8314 - accuracy: 0.6320 - val_loss: 0.7654 - val_accuracy: 0.6510\n",
      "Epoch 282/2000\n",
      "245/245 [==============================] - 0s 674us/step - loss: 0.8355 - accuracy: 0.6288 - val_loss: 0.7661 - val_accuracy: 0.6556\n",
      "Epoch 283/2000\n",
      "245/245 [==============================] - 0s 672us/step - loss: 0.8325 - accuracy: 0.6402 - val_loss: 0.7676 - val_accuracy: 0.6531\n",
      "Epoch 284/2000\n",
      "245/245 [==============================] - 0s 675us/step - loss: 0.8366 - accuracy: 0.6339 - val_loss: 0.7654 - val_accuracy: 0.6413\n",
      "Epoch 285/2000\n",
      "245/245 [==============================] - 0s 654us/step - loss: 0.8371 - accuracy: 0.6340 - val_loss: 0.7648 - val_accuracy: 0.6520\n",
      "Epoch 286/2000\n",
      "245/245 [==============================] - 0s 678us/step - loss: 0.8256 - accuracy: 0.6369 - val_loss: 0.7672 - val_accuracy: 0.6495\n",
      "Epoch 287/2000\n",
      "245/245 [==============================] - 0s 713us/step - loss: 0.8228 - accuracy: 0.6333 - val_loss: 0.7665 - val_accuracy: 0.6464\n",
      "Epoch 288/2000\n",
      "245/245 [==============================] - 0s 707us/step - loss: 0.8297 - accuracy: 0.6369 - val_loss: 0.7598 - val_accuracy: 0.6500\n",
      "Epoch 289/2000\n",
      "245/245 [==============================] - 0s 685us/step - loss: 0.8312 - accuracy: 0.6369 - val_loss: 0.7631 - val_accuracy: 0.6582\n",
      "Epoch 290/2000\n",
      "245/245 [==============================] - 0s 676us/step - loss: 0.8290 - accuracy: 0.6353 - val_loss: 0.7603 - val_accuracy: 0.6653\n",
      "Epoch 291/2000\n",
      "245/245 [==============================] - 0s 687us/step - loss: 0.8386 - accuracy: 0.6287 - val_loss: 0.7643 - val_accuracy: 0.6541\n",
      "Epoch 292/2000\n",
      "245/245 [==============================] - 0s 689us/step - loss: 0.8322 - accuracy: 0.6329 - val_loss: 0.7625 - val_accuracy: 0.6510\n",
      "Epoch 293/2000\n",
      "245/245 [==============================] - 0s 690us/step - loss: 0.8269 - accuracy: 0.6284 - val_loss: 0.7674 - val_accuracy: 0.6469\n",
      "Epoch 294/2000\n",
      "245/245 [==============================] - 0s 676us/step - loss: 0.8383 - accuracy: 0.6269 - val_loss: 0.7668 - val_accuracy: 0.6418\n",
      "Epoch 295/2000\n",
      "245/245 [==============================] - 0s 699us/step - loss: 0.8317 - accuracy: 0.6320 - val_loss: 0.7646 - val_accuracy: 0.6480\n",
      "Epoch 296/2000\n",
      "245/245 [==============================] - 0s 662us/step - loss: 0.8302 - accuracy: 0.6351 - val_loss: 0.7643 - val_accuracy: 0.6546\n",
      "Epoch 297/2000\n",
      "245/245 [==============================] - 0s 650us/step - loss: 0.8270 - accuracy: 0.6394 - val_loss: 0.7676 - val_accuracy: 0.6546\n",
      "Epoch 298/2000\n",
      "245/245 [==============================] - 0s 650us/step - loss: 0.8240 - accuracy: 0.6384 - val_loss: 0.7609 - val_accuracy: 0.6541\n",
      "Epoch 299/2000\n",
      "245/245 [==============================] - 0s 673us/step - loss: 0.8244 - accuracy: 0.6383 - val_loss: 0.7621 - val_accuracy: 0.6520\n",
      "Epoch 300/2000\n",
      "245/245 [==============================] - 0s 730us/step - loss: 0.8286 - accuracy: 0.6370 - val_loss: 0.7619 - val_accuracy: 0.6500\n",
      "Epoch 301/2000\n",
      "245/245 [==============================] - 0s 674us/step - loss: 0.8221 - accuracy: 0.6362 - val_loss: 0.7644 - val_accuracy: 0.6434\n",
      "Epoch 302/2000\n",
      "245/245 [==============================] - 0s 653us/step - loss: 0.8302 - accuracy: 0.6316 - val_loss: 0.7604 - val_accuracy: 0.6485\n",
      "Epoch 303/2000\n",
      "245/245 [==============================] - 0s 673us/step - loss: 0.8291 - accuracy: 0.6353 - val_loss: 0.7614 - val_accuracy: 0.6531\n",
      "Epoch 304/2000\n",
      "245/245 [==============================] - 0s 719us/step - loss: 0.8265 - accuracy: 0.6374 - val_loss: 0.7650 - val_accuracy: 0.6515\n",
      "Epoch 305/2000\n",
      "245/245 [==============================] - 0s 674us/step - loss: 0.8285 - accuracy: 0.6349 - val_loss: 0.7609 - val_accuracy: 0.6490\n",
      "Epoch 306/2000\n",
      "245/245 [==============================] - 0s 670us/step - loss: 0.8200 - accuracy: 0.6381 - val_loss: 0.7585 - val_accuracy: 0.6500\n",
      "Epoch 307/2000\n",
      "245/245 [==============================] - 0s 707us/step - loss: 0.8310 - accuracy: 0.6375 - val_loss: 0.7586 - val_accuracy: 0.6622\n",
      "Epoch 308/2000\n",
      "245/245 [==============================] - 0s 668us/step - loss: 0.8313 - accuracy: 0.6243 - val_loss: 0.7639 - val_accuracy: 0.6403\n",
      "Epoch 309/2000\n",
      "245/245 [==============================] - 0s 686us/step - loss: 0.8284 - accuracy: 0.6360 - val_loss: 0.7589 - val_accuracy: 0.6454\n",
      "Epoch 310/2000\n",
      "245/245 [==============================] - 0s 719us/step - loss: 0.8256 - accuracy: 0.6300 - val_loss: 0.7583 - val_accuracy: 0.6439\n",
      "Epoch 311/2000\n",
      "245/245 [==============================] - 0s 712us/step - loss: 0.8213 - accuracy: 0.6363 - val_loss: 0.7556 - val_accuracy: 0.6551\n",
      "Epoch 312/2000\n",
      "245/245 [==============================] - 0s 743us/step - loss: 0.8252 - accuracy: 0.6370 - val_loss: 0.7558 - val_accuracy: 0.6464\n",
      "Epoch 313/2000\n",
      "245/245 [==============================] - 0s 716us/step - loss: 0.8229 - accuracy: 0.6404 - val_loss: 0.7616 - val_accuracy: 0.6469\n",
      "Epoch 314/2000\n",
      "245/245 [==============================] - 0s 675us/step - loss: 0.8313 - accuracy: 0.6351 - val_loss: 0.7564 - val_accuracy: 0.6597\n",
      "Epoch 315/2000\n",
      "245/245 [==============================] - 0s 705us/step - loss: 0.8285 - accuracy: 0.6358 - val_loss: 0.7550 - val_accuracy: 0.6490\n",
      "Epoch 316/2000\n",
      "245/245 [==============================] - 0s 690us/step - loss: 0.8346 - accuracy: 0.6278 - val_loss: 0.7602 - val_accuracy: 0.6546\n",
      "Epoch 317/2000\n",
      "245/245 [==============================] - 0s 695us/step - loss: 0.8240 - accuracy: 0.6376 - val_loss: 0.7576 - val_accuracy: 0.6474\n",
      "Epoch 318/2000\n",
      "245/245 [==============================] - 0s 660us/step - loss: 0.8265 - accuracy: 0.6348 - val_loss: 0.7609 - val_accuracy: 0.6459\n",
      "Epoch 319/2000\n",
      "245/245 [==============================] - 0s 664us/step - loss: 0.8173 - accuracy: 0.6457 - val_loss: 0.7575 - val_accuracy: 0.6500\n",
      "Epoch 320/2000\n",
      "245/245 [==============================] - 0s 654us/step - loss: 0.8185 - accuracy: 0.6421 - val_loss: 0.7542 - val_accuracy: 0.6566\n",
      "Epoch 321/2000\n",
      "245/245 [==============================] - 0s 684us/step - loss: 0.8262 - accuracy: 0.6363 - val_loss: 0.7554 - val_accuracy: 0.6536\n",
      "Epoch 322/2000\n",
      "245/245 [==============================] - 0s 667us/step - loss: 0.8216 - accuracy: 0.6381 - val_loss: 0.7572 - val_accuracy: 0.6561\n",
      "Epoch 323/2000\n",
      "245/245 [==============================] - 0s 665us/step - loss: 0.8259 - accuracy: 0.6344 - val_loss: 0.7599 - val_accuracy: 0.6551\n",
      "Epoch 324/2000\n",
      "245/245 [==============================] - 0s 691us/step - loss: 0.8272 - accuracy: 0.6339 - val_loss: 0.7582 - val_accuracy: 0.6526\n",
      "Epoch 325/2000\n",
      "245/245 [==============================] - 0s 668us/step - loss: 0.8219 - accuracy: 0.6352 - val_loss: 0.7559 - val_accuracy: 0.6561\n",
      "Epoch 326/2000\n",
      "245/245 [==============================] - 0s 661us/step - loss: 0.8209 - accuracy: 0.6409 - val_loss: 0.7526 - val_accuracy: 0.6546\n",
      "Epoch 327/2000\n",
      "245/245 [==============================] - 0s 660us/step - loss: 0.8181 - accuracy: 0.6386 - val_loss: 0.7549 - val_accuracy: 0.6566\n",
      "Epoch 328/2000\n",
      "245/245 [==============================] - 0s 654us/step - loss: 0.8302 - accuracy: 0.6326 - val_loss: 0.7565 - val_accuracy: 0.6541\n",
      "Epoch 329/2000\n",
      "245/245 [==============================] - 0s 667us/step - loss: 0.8160 - accuracy: 0.6439 - val_loss: 0.7559 - val_accuracy: 0.6495\n",
      "Epoch 330/2000\n",
      "245/245 [==============================] - 0s 674us/step - loss: 0.8126 - accuracy: 0.6414 - val_loss: 0.7531 - val_accuracy: 0.6526\n",
      "Epoch 331/2000\n",
      "245/245 [==============================] - 0s 660us/step - loss: 0.8238 - accuracy: 0.6371 - val_loss: 0.7547 - val_accuracy: 0.6546\n",
      "Epoch 332/2000\n",
      "245/245 [==============================] - 0s 673us/step - loss: 0.8196 - accuracy: 0.6374 - val_loss: 0.7538 - val_accuracy: 0.6526\n",
      "Epoch 333/2000\n",
      "245/245 [==============================] - 0s 657us/step - loss: 0.8189 - accuracy: 0.6380 - val_loss: 0.7591 - val_accuracy: 0.6520\n",
      "Epoch 334/2000\n",
      "245/245 [==============================] - 0s 662us/step - loss: 0.8209 - accuracy: 0.6376 - val_loss: 0.7498 - val_accuracy: 0.6556\n",
      "Epoch 335/2000\n",
      "245/245 [==============================] - 0s 694us/step - loss: 0.8211 - accuracy: 0.6398 - val_loss: 0.7496 - val_accuracy: 0.6551\n",
      "Epoch 336/2000\n",
      "245/245 [==============================] - 0s 654us/step - loss: 0.8172 - accuracy: 0.6464 - val_loss: 0.7486 - val_accuracy: 0.6597\n",
      "Epoch 337/2000\n",
      "245/245 [==============================] - 0s 659us/step - loss: 0.8166 - accuracy: 0.6352 - val_loss: 0.7504 - val_accuracy: 0.6582\n",
      "Epoch 338/2000\n",
      "245/245 [==============================] - 0s 657us/step - loss: 0.8211 - accuracy: 0.6413 - val_loss: 0.7522 - val_accuracy: 0.6566\n",
      "Epoch 339/2000\n",
      "245/245 [==============================] - 0s 657us/step - loss: 0.8154 - accuracy: 0.6404 - val_loss: 0.7500 - val_accuracy: 0.6561\n",
      "Epoch 340/2000\n",
      "245/245 [==============================] - 0s 655us/step - loss: 0.8223 - accuracy: 0.6413 - val_loss: 0.7492 - val_accuracy: 0.6577\n",
      "Epoch 341/2000\n",
      "245/245 [==============================] - 0s 664us/step - loss: 0.8137 - accuracy: 0.6450 - val_loss: 0.7464 - val_accuracy: 0.6556\n",
      "Epoch 342/2000\n",
      "245/245 [==============================] - 0s 703us/step - loss: 0.8198 - accuracy: 0.6361 - val_loss: 0.7560 - val_accuracy: 0.6495\n",
      "Epoch 343/2000\n",
      "245/245 [==============================] - 0s 703us/step - loss: 0.8142 - accuracy: 0.6417 - val_loss: 0.7462 - val_accuracy: 0.6597\n",
      "Epoch 344/2000\n",
      "245/245 [==============================] - 0s 711us/step - loss: 0.8057 - accuracy: 0.6446 - val_loss: 0.7456 - val_accuracy: 0.6668\n",
      "Epoch 345/2000\n",
      "245/245 [==============================] - 0s 706us/step - loss: 0.8199 - accuracy: 0.6354 - val_loss: 0.7468 - val_accuracy: 0.6648\n",
      "Epoch 346/2000\n",
      "245/245 [==============================] - 0s 694us/step - loss: 0.8105 - accuracy: 0.6451 - val_loss: 0.7470 - val_accuracy: 0.6633\n",
      "Epoch 347/2000\n",
      "245/245 [==============================] - 0s 694us/step - loss: 0.8180 - accuracy: 0.6383 - val_loss: 0.7485 - val_accuracy: 0.6587\n",
      "Epoch 348/2000\n",
      "245/245 [==============================] - 0s 670us/step - loss: 0.8196 - accuracy: 0.6383 - val_loss: 0.7481 - val_accuracy: 0.6668\n",
      "Epoch 349/2000\n",
      "245/245 [==============================] - 0s 664us/step - loss: 0.8126 - accuracy: 0.6400 - val_loss: 0.7499 - val_accuracy: 0.6643\n",
      "Epoch 350/2000\n",
      "245/245 [==============================] - 0s 670us/step - loss: 0.8155 - accuracy: 0.6449 - val_loss: 0.7507 - val_accuracy: 0.6587\n",
      "Epoch 351/2000\n",
      "245/245 [==============================] - 0s 676us/step - loss: 0.8171 - accuracy: 0.6393 - val_loss: 0.7464 - val_accuracy: 0.6612\n",
      "Epoch 352/2000\n",
      "245/245 [==============================] - 0s 656us/step - loss: 0.8175 - accuracy: 0.6403 - val_loss: 0.7438 - val_accuracy: 0.6546\n",
      "Epoch 353/2000\n",
      "245/245 [==============================] - 0s 654us/step - loss: 0.8075 - accuracy: 0.6418 - val_loss: 0.7461 - val_accuracy: 0.6566\n",
      "Epoch 354/2000\n",
      "245/245 [==============================] - 0s 672us/step - loss: 0.8101 - accuracy: 0.6444 - val_loss: 0.7461 - val_accuracy: 0.6602\n",
      "Epoch 355/2000\n",
      "245/245 [==============================] - 0s 660us/step - loss: 0.8152 - accuracy: 0.6425 - val_loss: 0.7524 - val_accuracy: 0.6587\n",
      "Epoch 356/2000\n",
      "245/245 [==============================] - 0s 662us/step - loss: 0.8125 - accuracy: 0.6389 - val_loss: 0.7446 - val_accuracy: 0.6520\n",
      "Epoch 357/2000\n",
      "245/245 [==============================] - 0s 672us/step - loss: 0.8170 - accuracy: 0.6463 - val_loss: 0.7463 - val_accuracy: 0.6607\n",
      "Epoch 358/2000\n",
      "245/245 [==============================] - 0s 692us/step - loss: 0.8072 - accuracy: 0.6454 - val_loss: 0.7430 - val_accuracy: 0.6643\n",
      "Epoch 359/2000\n",
      "245/245 [==============================] - 0s 667us/step - loss: 0.8127 - accuracy: 0.6441 - val_loss: 0.7441 - val_accuracy: 0.6653\n",
      "Epoch 360/2000\n",
      "245/245 [==============================] - 0s 649us/step - loss: 0.8126 - accuracy: 0.6432 - val_loss: 0.7430 - val_accuracy: 0.6684\n",
      "Epoch 361/2000\n",
      "245/245 [==============================] - 0s 659us/step - loss: 0.8113 - accuracy: 0.6471 - val_loss: 0.7449 - val_accuracy: 0.6622\n",
      "Epoch 362/2000\n",
      "245/245 [==============================] - 0s 658us/step - loss: 0.8108 - accuracy: 0.6446 - val_loss: 0.7438 - val_accuracy: 0.6566\n",
      "Epoch 363/2000\n",
      "245/245 [==============================] - 0s 658us/step - loss: 0.8132 - accuracy: 0.6450 - val_loss: 0.7388 - val_accuracy: 0.6663\n",
      "Epoch 364/2000\n",
      "245/245 [==============================] - 0s 663us/step - loss: 0.8118 - accuracy: 0.6477 - val_loss: 0.7425 - val_accuracy: 0.6709\n",
      "Epoch 365/2000\n",
      "245/245 [==============================] - 0s 691us/step - loss: 0.8139 - accuracy: 0.6380 - val_loss: 0.7445 - val_accuracy: 0.6679\n",
      "Epoch 366/2000\n",
      "245/245 [==============================] - 0s 670us/step - loss: 0.8094 - accuracy: 0.6457 - val_loss: 0.7422 - val_accuracy: 0.6668\n",
      "Epoch 367/2000\n",
      "245/245 [==============================] - 0s 654us/step - loss: 0.8068 - accuracy: 0.6421 - val_loss: 0.7422 - val_accuracy: 0.6679\n",
      "Epoch 368/2000\n",
      "245/245 [==============================] - 0s 672us/step - loss: 0.8132 - accuracy: 0.6390 - val_loss: 0.7473 - val_accuracy: 0.6602\n",
      "Epoch 369/2000\n",
      "245/245 [==============================] - 0s 691us/step - loss: 0.8126 - accuracy: 0.6459 - val_loss: 0.7429 - val_accuracy: 0.6643\n",
      "Epoch 370/2000\n",
      "245/245 [==============================] - 0s 665us/step - loss: 0.8128 - accuracy: 0.6473 - val_loss: 0.7410 - val_accuracy: 0.6704\n",
      "Epoch 371/2000\n",
      "245/245 [==============================] - 0s 684us/step - loss: 0.8040 - accuracy: 0.6491 - val_loss: 0.7427 - val_accuracy: 0.6602\n",
      "Epoch 372/2000\n",
      "245/245 [==============================] - 0s 669us/step - loss: 0.8106 - accuracy: 0.6462 - val_loss: 0.7396 - val_accuracy: 0.6653\n",
      "Epoch 373/2000\n",
      "245/245 [==============================] - 0s 669us/step - loss: 0.8109 - accuracy: 0.6412 - val_loss: 0.7401 - val_accuracy: 0.6679\n",
      "Epoch 374/2000\n",
      "245/245 [==============================] - 0s 655us/step - loss: 0.8097 - accuracy: 0.6409 - val_loss: 0.7435 - val_accuracy: 0.6663\n",
      "Epoch 375/2000\n",
      "245/245 [==============================] - 0s 671us/step - loss: 0.8054 - accuracy: 0.6531 - val_loss: 0.7448 - val_accuracy: 0.6551\n",
      "Epoch 376/2000\n",
      "245/245 [==============================] - 0s 667us/step - loss: 0.8132 - accuracy: 0.6436 - val_loss: 0.7416 - val_accuracy: 0.6633\n",
      "Epoch 377/2000\n",
      "245/245 [==============================] - 0s 671us/step - loss: 0.8116 - accuracy: 0.6369 - val_loss: 0.7424 - val_accuracy: 0.6602\n",
      "Epoch 378/2000\n",
      "245/245 [==============================] - 0s 671us/step - loss: 0.8061 - accuracy: 0.6485 - val_loss: 0.7416 - val_accuracy: 0.6643\n",
      "Epoch 379/2000\n",
      "245/245 [==============================] - 0s 664us/step - loss: 0.8087 - accuracy: 0.6474 - val_loss: 0.7438 - val_accuracy: 0.6582\n",
      "Epoch 380/2000\n",
      "245/245 [==============================] - 0s 685us/step - loss: 0.8031 - accuracy: 0.6520 - val_loss: 0.7356 - val_accuracy: 0.6684\n",
      "Epoch 381/2000\n",
      "245/245 [==============================] - 0s 689us/step - loss: 0.8097 - accuracy: 0.6394 - val_loss: 0.7453 - val_accuracy: 0.6536\n",
      "Epoch 382/2000\n",
      "245/245 [==============================] - 0s 674us/step - loss: 0.8022 - accuracy: 0.6458 - val_loss: 0.7372 - val_accuracy: 0.6699\n",
      "Epoch 383/2000\n",
      "245/245 [==============================] - 0s 646us/step - loss: 0.8044 - accuracy: 0.6491 - val_loss: 0.7419 - val_accuracy: 0.6612\n",
      "Epoch 384/2000\n",
      "245/245 [==============================] - 0s 669us/step - loss: 0.8093 - accuracy: 0.6422 - val_loss: 0.7421 - val_accuracy: 0.6689\n",
      "Epoch 385/2000\n",
      "245/245 [==============================] - 0s 688us/step - loss: 0.8019 - accuracy: 0.6431 - val_loss: 0.7412 - val_accuracy: 0.6643\n",
      "Epoch 386/2000\n",
      "245/245 [==============================] - 0s 684us/step - loss: 0.8130 - accuracy: 0.6469 - val_loss: 0.7381 - val_accuracy: 0.6643\n",
      "Epoch 387/2000\n",
      "245/245 [==============================] - 0s 671us/step - loss: 0.8012 - accuracy: 0.6518 - val_loss: 0.7373 - val_accuracy: 0.6699\n",
      "Epoch 388/2000\n",
      "245/245 [==============================] - 0s 688us/step - loss: 0.8014 - accuracy: 0.6508 - val_loss: 0.7362 - val_accuracy: 0.6679\n",
      "Epoch 389/2000\n",
      "245/245 [==============================] - 0s 686us/step - loss: 0.8033 - accuracy: 0.6533 - val_loss: 0.7341 - val_accuracy: 0.6679\n",
      "Epoch 390/2000\n",
      "245/245 [==============================] - 0s 695us/step - loss: 0.8094 - accuracy: 0.6418 - val_loss: 0.7359 - val_accuracy: 0.6709\n",
      "Epoch 391/2000\n",
      "245/245 [==============================] - 0s 706us/step - loss: 0.8065 - accuracy: 0.6445 - val_loss: 0.7356 - val_accuracy: 0.6709\n",
      "Epoch 392/2000\n",
      "245/245 [==============================] - 0s 661us/step - loss: 0.7999 - accuracy: 0.6426 - val_loss: 0.7365 - val_accuracy: 0.6679\n",
      "Epoch 393/2000\n",
      "245/245 [==============================] - 0s 666us/step - loss: 0.8032 - accuracy: 0.6480 - val_loss: 0.7395 - val_accuracy: 0.6684\n",
      "Epoch 394/2000\n",
      "245/245 [==============================] - 0s 657us/step - loss: 0.8024 - accuracy: 0.6477 - val_loss: 0.7338 - val_accuracy: 0.6765\n",
      "Epoch 395/2000\n",
      "245/245 [==============================] - 0s 663us/step - loss: 0.8011 - accuracy: 0.6476 - val_loss: 0.7336 - val_accuracy: 0.6709\n",
      "Epoch 396/2000\n",
      "245/245 [==============================] - 0s 670us/step - loss: 0.8104 - accuracy: 0.6469 - val_loss: 0.7383 - val_accuracy: 0.6740\n",
      "Epoch 397/2000\n",
      "245/245 [==============================] - 0s 648us/step - loss: 0.8069 - accuracy: 0.6449 - val_loss: 0.7404 - val_accuracy: 0.6653\n",
      "Epoch 398/2000\n",
      "245/245 [==============================] - 0s 668us/step - loss: 0.7986 - accuracy: 0.6471 - val_loss: 0.7394 - val_accuracy: 0.6648\n",
      "Epoch 399/2000\n",
      "245/245 [==============================] - 0s 666us/step - loss: 0.8023 - accuracy: 0.6485 - val_loss: 0.7369 - val_accuracy: 0.6719\n",
      "Epoch 400/2000\n",
      "245/245 [==============================] - 0s 664us/step - loss: 0.8045 - accuracy: 0.6473 - val_loss: 0.7366 - val_accuracy: 0.6679\n",
      "Epoch 401/2000\n",
      "245/245 [==============================] - 0s 692us/step - loss: 0.8050 - accuracy: 0.6472 - val_loss: 0.7421 - val_accuracy: 0.6668\n",
      "Epoch 402/2000\n",
      "245/245 [==============================] - 0s 676us/step - loss: 0.8064 - accuracy: 0.6450 - val_loss: 0.7385 - val_accuracy: 0.6714\n",
      "Epoch 403/2000\n",
      "245/245 [==============================] - 0s 669us/step - loss: 0.8031 - accuracy: 0.6439 - val_loss: 0.7316 - val_accuracy: 0.6750\n",
      "Epoch 404/2000\n",
      "245/245 [==============================] - 0s 662us/step - loss: 0.7938 - accuracy: 0.6482 - val_loss: 0.7346 - val_accuracy: 0.6673\n",
      "Epoch 405/2000\n",
      "245/245 [==============================] - 0s 678us/step - loss: 0.8026 - accuracy: 0.6462 - val_loss: 0.7399 - val_accuracy: 0.6673\n",
      "Epoch 406/2000\n",
      "245/245 [==============================] - 0s 680us/step - loss: 0.8021 - accuracy: 0.6471 - val_loss: 0.7368 - val_accuracy: 0.6658\n",
      "Epoch 407/2000\n",
      "245/245 [==============================] - 0s 665us/step - loss: 0.8044 - accuracy: 0.6445 - val_loss: 0.7326 - val_accuracy: 0.6755\n",
      "Epoch 408/2000\n",
      "245/245 [==============================] - 0s 676us/step - loss: 0.8035 - accuracy: 0.6524 - val_loss: 0.7352 - val_accuracy: 0.6719\n",
      "Epoch 409/2000\n",
      "245/245 [==============================] - 0s 641us/step - loss: 0.7918 - accuracy: 0.6473 - val_loss: 0.7329 - val_accuracy: 0.6745\n",
      "Epoch 410/2000\n",
      "245/245 [==============================] - 0s 661us/step - loss: 0.7989 - accuracy: 0.6490 - val_loss: 0.7400 - val_accuracy: 0.6730\n",
      "Epoch 411/2000\n",
      "245/245 [==============================] - 0s 692us/step - loss: 0.8007 - accuracy: 0.6497 - val_loss: 0.7299 - val_accuracy: 0.6760\n",
      "Epoch 412/2000\n",
      "245/245 [==============================] - 0s 678us/step - loss: 0.8028 - accuracy: 0.6536 - val_loss: 0.7312 - val_accuracy: 0.6714\n",
      "Epoch 413/2000\n",
      "245/245 [==============================] - 0s 669us/step - loss: 0.7919 - accuracy: 0.6531 - val_loss: 0.7313 - val_accuracy: 0.6724\n",
      "Epoch 414/2000\n",
      "245/245 [==============================] - 0s 667us/step - loss: 0.7979 - accuracy: 0.6492 - val_loss: 0.7281 - val_accuracy: 0.6760\n",
      "Epoch 415/2000\n",
      "245/245 [==============================] - 0s 672us/step - loss: 0.7954 - accuracy: 0.6533 - val_loss: 0.7311 - val_accuracy: 0.6745\n",
      "Epoch 416/2000\n",
      "245/245 [==============================] - 0s 679us/step - loss: 0.7967 - accuracy: 0.6492 - val_loss: 0.7330 - val_accuracy: 0.6719\n",
      "Epoch 417/2000\n",
      "245/245 [==============================] - 0s 682us/step - loss: 0.7940 - accuracy: 0.6525 - val_loss: 0.7297 - val_accuracy: 0.6765\n",
      "Epoch 418/2000\n",
      "245/245 [==============================] - 0s 680us/step - loss: 0.7923 - accuracy: 0.6584 - val_loss: 0.7299 - val_accuracy: 0.6796\n",
      "Epoch 419/2000\n",
      "245/245 [==============================] - 0s 662us/step - loss: 0.8028 - accuracy: 0.6440 - val_loss: 0.7339 - val_accuracy: 0.6760\n",
      "Epoch 420/2000\n",
      "245/245 [==============================] - 0s 649us/step - loss: 0.7968 - accuracy: 0.6436 - val_loss: 0.7314 - val_accuracy: 0.6786\n",
      "Epoch 421/2000\n",
      "245/245 [==============================] - 0s 694us/step - loss: 0.7972 - accuracy: 0.6454 - val_loss: 0.7256 - val_accuracy: 0.6755\n",
      "Epoch 422/2000\n",
      "245/245 [==============================] - 0s 667us/step - loss: 0.8006 - accuracy: 0.6467 - val_loss: 0.7308 - val_accuracy: 0.6760\n",
      "Epoch 423/2000\n",
      "245/245 [==============================] - 0s 687us/step - loss: 0.7981 - accuracy: 0.6550 - val_loss: 0.7325 - val_accuracy: 0.6816\n",
      "Epoch 424/2000\n",
      "245/245 [==============================] - 0s 670us/step - loss: 0.8000 - accuracy: 0.6504 - val_loss: 0.7279 - val_accuracy: 0.6776\n",
      "Epoch 425/2000\n",
      "245/245 [==============================] - 0s 683us/step - loss: 0.7994 - accuracy: 0.6482 - val_loss: 0.7253 - val_accuracy: 0.6837\n",
      "Epoch 426/2000\n",
      "245/245 [==============================] - 0s 661us/step - loss: 0.7968 - accuracy: 0.6537 - val_loss: 0.7254 - val_accuracy: 0.6832\n",
      "Epoch 427/2000\n",
      "245/245 [==============================] - 0s 727us/step - loss: 0.8009 - accuracy: 0.6463 - val_loss: 0.7272 - val_accuracy: 0.6821\n",
      "Epoch 428/2000\n",
      "245/245 [==============================] - 0s 725us/step - loss: 0.7793 - accuracy: 0.6591 - val_loss: 0.7290 - val_accuracy: 0.6745\n",
      "Epoch 429/2000\n",
      "245/245 [==============================] - 0s 692us/step - loss: 0.8007 - accuracy: 0.6472 - val_loss: 0.7296 - val_accuracy: 0.6821\n",
      "Epoch 430/2000\n",
      "245/245 [==============================] - 0s 702us/step - loss: 0.7962 - accuracy: 0.6495 - val_loss: 0.7239 - val_accuracy: 0.6872\n",
      "Epoch 431/2000\n",
      "245/245 [==============================] - 0s 673us/step - loss: 0.8025 - accuracy: 0.6468 - val_loss: 0.7285 - val_accuracy: 0.6760\n",
      "Epoch 432/2000\n",
      "245/245 [==============================] - 0s 670us/step - loss: 0.8026 - accuracy: 0.6467 - val_loss: 0.7265 - val_accuracy: 0.6908\n",
      "Epoch 433/2000\n",
      " 87/245 [=========>....................] - ETA: 0s - loss: 0.7905 - accuracy: 0.6498"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m get_datos(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdominance_tags\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m dominance_tags_model, dominance_tags_model_fit \u001b[38;5;241m=\u001b[39m \u001b[43mget_moddelo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[92], line 18\u001b[0m, in \u001b[0;36mget_moddelo\u001b[0;34m(x_train, x_test, y_train, y_test)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#model.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['accuracy'])\u001b[39;00m\n\u001b[1;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,optimizer\u001b[38;5;241m=\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m),metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 18\u001b[0m model_fit \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, model_fit\n",
      "File \u001b[0;32m/media/qwerty/RESPALDO/UBB/ml/Proyecto/.venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/media/qwerty/RESPALDO/UBB/ml/Proyecto/.venv/lib/python3.10/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/media/qwerty/RESPALDO/UBB/ml/Proyecto/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/media/qwerty/RESPALDO/UBB/ml/Proyecto/.venv/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/media/qwerty/RESPALDO/UBB/ml/Proyecto/.venv/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/media/qwerty/RESPALDO/UBB/ml/Proyecto/.venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/qwerty/RESPALDO/UBB/ml/Proyecto/.venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/media/qwerty/RESPALDO/UBB/ml/Proyecto/.venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/media/qwerty/RESPALDO/UBB/ml/Proyecto/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = get_datos(\"dominance_tags\")\n",
    "dominance_tags_model, dominance_tags_model_fit = get_moddelo(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{dominance_tags_model.evaluate(x_test, y_test)=}')\n",
    "print(f'{decision_tree(x_train, x_test, y_train, y_test)=}')\n",
    "print(f'{random_forest(x_train, x_test, y_train, y_test)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_graficos(dominance_tags_model, dominance_tags_model_fit, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = get_datos(\"arousal_tags\")\n",
    "arousal_tags_model, arousal_tags_model_fit = get_moddelo(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{dominance_tags_model.evaluate(x_test, y_test)=}')\n",
    "print(f'{decision_tree(dominance_tags_model, x_train, x_test, y_train, y_test)=}')\n",
    "print(f'{random_forest(dominance_tags_model, x_train, x_test, y_train, y_test)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_graficos(arousal_tags_model, arousal_tags_model_fit, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = get_datos(\"valence_tags\")\n",
    "valence_tags_model, valence_tags_model_fit = get_moddelo(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{dominance_tags_model.evaluate(x_test, y_test)=}')\n",
    "print(f'{decision_tree(dominance_tags_model, x_train, x_test, y_train, y_test)=}')\n",
    "print(f'{random_forest(dominance_tags_model, x_train, x_test, y_train, y_test)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_graficos(valence_tags_model, valence_tags_model_fit, x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
